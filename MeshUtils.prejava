#include "macros.h"

import com.donhatchsw.compat.ArrayList;
import com.donhatchsw.compat.IntArrayList;
import com.donhatchsw.util.Arrays;
import com.donhatchsw.util.FuzzyPointHashTable;
import com.donhatchsw.util.MergeFind;
import com.donhatchsw.util.MyMath;
import com.donhatchsw.util.SortStuff;
import com.donhatchsw.util.VecMath;

final public class MeshUtils
{
    private MeshUtils(){ throw new AssertionError(); } // non-instantiatable util class

    public static double[][/*2*/] getMeshVertsXY(Mesh mesh)
    {
        int nVerts = mesh.verts.size();
        double answer[][] = new double[nVerts][2];

        FORI (iVert, nVerts)
        {
            Mesh.Vertex v = mesh.getVert(iVert);
            answer[iVert][0] = v.x();
            answer[iVert][1] = v.y();
        }
        return answer;
    }

    public static double[][/*3*/] getMeshVertsXYH(Mesh mesh)
    {
        int nVerts = mesh.verts.size();
        double answer[][] = new double[nVerts][3];

        FORI (iVert, nVerts)
        {
            Mesh.Vertex v = mesh.getVert(iVert);
            answer[iVert][0] = v.x();
            answer[iVert][1] = v.y();
            answer[iVert][2] = v.h();
        }
        return answer;
    }

    // If canonicalOrder flag, order each face so that least-index vertex is first,
    // and then sort faces by increasing size and then increasing contents.
    // and then sort faces by increasing size and then contents.
    public static int[][] getMeshFaces(Mesh mesh, boolean canonicalOrderFlag)
    {
        boolean seenEdge[] = new boolean[mesh.edges.size()]; // all false initially
        int[][] faces = new int[mesh.edges.size()][];
        int[] scratchFace = new int[mesh.edges.size()]; // probably safer than mesh.verts.size()
        int nFaces = 0;
        FORIDOWN(iEdge, mesh.edges.size())
        {
            if (seenEdge[iEdge]) continue;
            Mesh.Edge edge0 = mesh.getEdge(iEdge);
            int faceSize = 0;
            Mesh.Edge edge = edge0;
            do {
                seenEdge[edge.myIndex()] = true;
                scratchFace[faceSize++] = edge.initialVertex().myIndex();
            } while ((edge = edge.next()) != edge0);
            faces[nFaces++] = (int[])Arrays.subarray(scratchFace, 0, faceSize);
        }
        faces = (int[][])Arrays.subarray(faces, 0, nFaces);

        if (canonicalOrderFlag)
        {
            FORIDOWN(iFace, faces.length)
            {
                int face[] = faces[iFace];
                int mini = VecMath.mini(face);
                System.arraycopy(face, mini,
                                 scratchFace, 0,
                                 face.length - mini);
                System.arraycopy(face, 0,
                                 scratchFace, face.length - mini,
                                 mini);
                System.arraycopy(scratchFace, 0,
                                 face, 0,
                                 face.length);
            }
            SortStuff.sort(faces, new SortStuff.Comparator() {
                @Override public int compare(Object a, Object b)
                {
                    // TODO: call it aFace, bFace
                    int aFace[] = (int[])a;
                    int bFace[] = (int[])b;
                    if (aFace.length < bFace.length) return -1;
                    if (aFace.length > bFace.length) return 1;
                    for (int i = 0; i < aFace.length; ++i)
                    {
                        if (aFace[i] < bFace[i]) return -1;
                        if (aFace[i] > bFace[i]) return 1;
                    }
                    return 0;
                }
            });
        }
        return faces;
    } // getMeshFaces

    // CBB: assumes mesh is triangulated
    public static int[] findPrimalFaceFromDualVert(Mesh mesh, Mesh dualMesh, int iDualVert)
    {
        int nEdges = dualMesh.edges.size();
        assert_eq(nEdges, mesh.edges.size());
        FORI (iEdge, nEdges)
        {
            Mesh.Edge dualEdge = dualMesh.getEdge(iEdge);
            Mesh.Vertex initialVertex = dualEdge.initialVertex();
            if (initialVertex != null
             && initialVertex.myIndex() == iDualVert)
            {
                Mesh.Edge primalEdge = (mesh.getEdge(iEdge)).opposite();
                assumpt(primalEdge.next().next().next() == primalEdge);
                // advance around triangle til initial vertex is smallest
                while (primalEdge.initialVertex().myIndex() > primalEdge.finalVertex().myIndex()
                    || primalEdge.initialVertex().myIndex() > primalEdge.prev().initialVertex().myIndex())
                    primalEdge = primalEdge.next();
                int i0 = primalEdge.initialVertex().myIndex();
                int i1 = primalEdge.finalVertex().myIndex();
                int i2 = primalEdge.prev().initialVertex().myIndex();
                return new int[] {i0,i1,i2};
            }
        }
        return null;
    } // findPrimalFaceFromDualVert

    private static double detNonDestructiveDouble(int n, BigInt M[/*n*/][/*n*/])
    {
        double Mdouble[][] = new double[n][n];
        for (int i = 0; i < n; ++i)
        for (int j = 0; j < n; ++j)
            Mdouble[i][j] = M[i][j].i.doubleValue();
        double answer = VecMath.detDestructive(Mdouble);
        return answer;
    }


    private static int[][] bitLengthsSigned(BigInt M[][])
    {
        int answer[][] = new int[M.length][];
        FORIDOWN (i, M.length)
        {
            answer[i] = new int[M[i].length];
            FORIDOWN (j, M[i].length)
            {
                answer[i][j] = M[i][j].signum() * M[i][j].bitLength();
            }
        }
        return answer;
    } // bitLengthsSigned

    // Return an array of BigInts whose product is the determinant in question.
    // First entry will be 1 or -1, the others will be positive.
    private static BigInt[] factorizeDetDestructive(int n, BigInt M[][])
    {
        int verboseLevel = 1;
        if (verboseLevel >= 1) OUT("        in factorizeDetDestructive(n="+n+")");
        if (verboseLevel >= 1) OUT("          before:");
        if (verboseLevel >= 1) PRINTMAT(M);
        if (verboseLevel >= 1) PRINT(n);

        BigInt maxEntryEver = new BigInt(0);

        int sign = 1;
        FORI (i, n)
        {
            if (verboseLevel >= 2) OUT("              i="+i);
            if (verboseLevel >= 2) PRINTMAT(M);

            boolean pivotFlag = true;
            if (pivotFlag)
            {
                // Optional, but helps keep numbers relatively small:
                // Choose the pivot to be the smallest-magnitude nonzero entry in [>=i][>=i].
                // This is a heuristic; I actually don't know the best way
                // to do this.
                // Actually, I think we *have* to pivot somewhat, at least to make [i][i] nonzero, don't we?
                //
                // Ideas:
                //   - start with the least-complicated-looking minor
                //   - transpose remaining part freely.
                //   - choose the column (or row) with the least gcd (1 if possible)
                //   - in that column, sort the entries so we deal with smallest first,
                //     to get to gcd as fast as possible
                //   - actually fully diagonalize rather than just upper-triangulate? (HUGE WIN!) (ARGH but I messed up and it's not really diagonalizing!  But it's a huge win anyway!! wtf?
                int jPivot = -1;
                int kPivot = -1;
                BigInt absPivot = null;
                for (int j = i; j < n; ++j)
                for (int k = i; k < n; ++k)
                {
                    if (M[j][k].signum() != 0)
                    {
                        BigInt absEntry = M[j][k].abs();
                        if (absEntry.gt(maxEntryEver))
                            maxEntryEver.set(absEntry);
                        if (absPivot == null || absEntry.lt(absPivot))
                        {
                            jPivot = j;
                            kPivot = k;
                            absPivot = absEntry;
                        }
                    }
                }
                if (verboseLevel >= 2) OUT("              jPivot="+jPivot);
                if (verboseLevel >= 2) OUT("              kPivot="+kPivot);
                if (absPivot != null)
                {
                    if (jPivot != i)
                    {
                        BigInt temp[];
                        SWAP(M[i], M[jPivot], temp);
                        sign *= -1;
                    }
                    if (kPivot != i)
                    {
                        // CBB: maybe maintain a column permutation instead of all these swaps?
                        BigInt temp;
                        for (int j = i; j < n; ++j)
                            SWAP(M[j][i], M[j][kPivot], temp);
                        sign *= -1;
                    }
                }
                if (verboseLevel >= 2) OUT("                  after pivoting:");
                if (verboseLevel >= 2) PRINTMAT(M);
            }
            assert(M[i][i].signum() != 0); // XXX huh? why does this succeed, even without pivoting?


            boolean fullyDiagonalizeFlag = true; // huge win!  XXX OUCH but this isn't diagonalizing!  but it's a huge win anyway!
            int nPasses = fullyDiagonalizeFlag ? 2 : 1;
            FORI (iPass, nPasses)
            {
                // Make sure everything we're going to deal with in this column is nonnegative
                for (int j = i; j < n; ++j)
                {
                    if (M[j][i].signum() < 0)
                    {
                        sign *= -1;
                        for (int k = i; k < n; ++k)
                            M[j][k].timesEquals(-1);
                    }
                }
                if (verboseLevel >= 2) OUT("                  after nonnegativizing:");
                if (verboseLevel >= 2) PRINTMAT(M);

                // XXX what was this? fixing what?
                //if (verboseLevel >= 2) OUT("                  after fixing:");
                //if (verboseLevel >= 2) PRINTMAT(M);


                // Zero out all entries [>i][i]
                // by doing row operations against row i.
                // What's left in [i][i] afterwards will be the gcd of [>=i][i].
                for (int j = i+1; j < n; ++j)
                {
                    if (verboseLevel >= 3) OUT("                  j="+j);
                    assert_ge(M[j][i].signum(), 0);
                    if (true)
                    {
                        int iters = 0;
                        int maxIters = 20000; // holy moly! 1000 wasn't enough, for a 100-node blue noise, needed 16109. the numbers got super big. any way to prevent this?? the final number isn't that big!
                        while (M[j][i].signum() != 0)
                        {
                            iters++;
                            //assert_lt(iters, maxIters);
                            if (iters > maxIters)
                            {
                                OUT("HEY! iters="+iters+" > maxIters="+maxIters);
                            }
                            BigInt a = M[i][i];
                            BigInt b = M[j][i];
                            if (verboseLevel >= 3) OUT("                      a = "+a);
                            if (verboseLevel >= 3) OUT("                      b = "+b);
                            java.math.BigInteger q = a.i.divide(b.i);
                            // a,b = b,a%b
                            // One step in euclidean algorithm: a -= q * b, then swap a,b
                            // Do it to the whole row.
                            for (int k = i; k < n; ++k)
                            {
                                //M[i][k] -= q * M[j][k];
                                M[i][k].minusEquals(M[j][k].i.multiply(q));
                            }
                            BigInt temp[];
                            SWAP(M[i], M[j], temp);
                            sign *= -1;
                        }
                    }
                    else if (true)
                    {
                        // How to do that better?
                        // Well, if a = M[i][i], b = M[j][i], g = gcd(a,b),
                        // want to reduce [i][i] to g and [j][i] to 0,
                        // using row operations.

                        // How to do that better?
                        // Well, if a = M[i][i], b = M[j][i], g = gcd(a,b),
                        // want to reduce [i][i] to g and [j][i] to 0,
                        // using row operations.
                        // I.e. we want to multiply by some 2x2 matrix with det=1 on the left.
                        // That is, we want a 2x2 matrix R, with determinant 1, such that:
                        // R * [a] = [g]
                        //     [b]   [0]
                        // Well, let x,y be such that a*x + b*y == g,
                        // i.e. (a/g)*x + (b/g)*y == 1.
                        // then we can let:
                        //    R = [  x   y ]
                        //        [-b/g a/g]
                        // Then R has the desired properties.
                        java.math.BigInteger a = M[i][i].i;
                        java.math.BigInteger b = M[j][i].i;
                        java.math.BigInteger coeffs[] = new java.math.BigInteger[2];
                        java.math.BigInteger g = BigInt.gcdExtended(a, b, coeffs);
                        java.math.BigInteger x = coeffs[0];
                        java.math.BigInteger y = coeffs[1];
                        java.math.BigInteger A = a.divide(g);
                        java.math.BigInteger B = b.divide(g);
                        assert(A.multiply(x).add(B.multiply(y)).equals(java.math.BigInteger.ONE));
                        for (int k = i; k < n; ++k)
                        {
                            // new M[i][k] =  x*M[i][k] + y*M[j][k]
                            // new M[j][k] = -B*M[i][k] + A*M[j][k]
                            java.math.BigInteger Mik = M[i][k].i;
                            java.math.BigInteger Mjk = M[j][k].i;
                            M[i][k].i = x.multiply(Mik).add(y.multiply(Mjk));
                            M[j][k].i = A.multiply(Mjk).subtract(B.multiply(Mik));
                        }
                        assert(M[i][i].i.equals(g));
                        assert(M[j][i].signum() == 0);
                    }
                } // for j

                if (iPass+1 < nPasses)
                {
                    if (verboseLevel >= 3) OUT("before transposing [>="+i+"]:");
                    if (verboseLevel >= 3) PRINTMAT(M);
                    // transpose [>=1][>=1] for second pass
                    BigInt temp;
                    for (int ii = i; ii < n; ++ii)
                    for (int jj = ii+1; jj < n; ++jj)
                    {
                        SWAP(M[ii][jj], M[jj][ii], temp);
                    }
                    if (verboseLevel >= 3) OUT("after transposing [>="+i+"]:");
                    if (verboseLevel >= 3) PRINTMAT(M);
                } else {
                    if (verboseLevel >= 3) OUT("final after i="+i+":");
                    if (verboseLevel >= 3) PRINTMAT(M);
                }

            } // for iPass
        } // for i
        if (verboseLevel >= 1) OUT("      after:");
        if (verboseLevel >= 2 || (verboseLevel>=1 && maxEntryEver.bitLength() <= 3000)) PRINTMAT(M);
        if (verboseLevel >= 1) PRINTMAT(bitLengthsSigned(M));

        BigInt answer[] = new BigInt[n+1];
        answer[0] = new BigInt(sign);
        for (int i = 0; i < n; ++i)
            answer[i+1] = M[i][i];
        if (verboseLevel >= 2 || (verboseLevel>=1 && maxEntryEver.bitLength() <= 3000)) OUT("      maxEntryEver = "+maxEntryEver);
        if (verboseLevel >= 1) OUT("      maxEntryEver.bitLength() = "+maxEntryEver.bitLength());
        if (false)
        {
            // very ad-hoc analyzing maxEntryEver.  bleah, not finding it to be very composite.
            System.out.print("      = ");
            System.out.flush();
            BigInt scratch = maxEntryEver.copy();
            BigInt scratch2 = new BigInt(0);
            if (scratch.ne(0))
                for (int i = 2; i < 10*1000*1000; ++i)
                {
                    if (i > 2 && i % 2 == 0) continue;
                    if (i > 3 && i % 3 == 0) continue;
                    if (i > 5 && i % 5 == 0) continue;
                    if (i > 7 && i % 7 == 0) continue;
                    if (i > 11 && i % 11 == 0) continue;
                    if (i > 13 && i % 13 == 0) continue;
                    if (i > 17 && i % 17 == 0) continue;
                    if (i > 19 && i % 19 == 0) continue;
                    if (i > 23 && i % 23 == 0) continue;
                    if (i > 29 && i % 29 == 0) continue;
                    if (i > 31 && i % 31 == 0) continue;
                    if (i > 37 && i % 37 == 0) continue;
                    scratch2.set(scratch);
                    while (scratch2.divEqualsReturningRemainder(i) == 0)
                    {
                        System.out.print(" "+i);
                        System.out.flush();
                        scratch.set(scratch2);
                    }
                }
            if (scratch.ne(1))
                System.out.print(" "+scratch);
            System.out.println();
        }
        if (verboseLevel >= 1) OUT("    out factorizeDetDestructive(n="+n+"), returning "+VecMath.toString(answer));
        return answer;
    } // factorizeDetDestructive
    // Unfortunately not sure whether I should be returning long or double.
    // Long might be more exact, but can overflow.
    private static BigInt detDestructiveBigInt(int n, BigInt M[][])
    {
        int verboseLevel = 1;
        if (verboseLevel >= 1) OUT("    in detDestructiveBigInt(n="+n+")");
        BigInt factors[] = factorizeDetDestructive(n, M);
        BigInt answer = new BigInt(1);
        for (int i = 0; i < factors.length; ++i)
            answer.timesEquals(factors[i]);
        if (verboseLevel >= 1) OUT("      answer.bitLength() "+answer.bitLength());
        if (verboseLevel >= 1) OUT("    out detDestructiveBigInt("+n+"), returning "+answer);
        return answer;
    }

    // Uses Kirchoff's theorem. https://en.wikipedia.org/wiki/Kirchhoff%27s_theorem.
    // Kinda sucks since it's either inexact or uses bigints whose intermediate values blow up super big :-(
    public static BigInt countSpanningTrees(Mesh mesh)
    {
        OUT("    in countSpanningTrees");
        int nVerts = mesh.verts.size();
        if (nVerts == 0)
            return new BigInt(0);
        BigInt laplacian[][] = new BigInt[nVerts+1][nVerts+1];
        for (int i = 0; i < laplacian.length; ++i)
        for (int j = 0; j < laplacian[0].length; ++j)
            laplacian[i][j] = new BigInt(0);

        int nEdges = mesh.edges.size();
        for (int iEdge = 0; iEdge < nEdges; ++iEdge)
        {
            Mesh.Edge edge = mesh.getEdge(iEdge);
            Mesh.Vertex v0 = edge.initialVertex();
            Mesh.Vertex v1 = edge.finalVertex();
            int i0 = v0==null ? nVerts : v0.myIndex();
            int i1 = v1==null ? nVerts : v1.myIndex();
            if (i0 != i1) // self-loops are irrelevant
            {
                laplacian[i0][i0].plusEquals(1);
                laplacian[i0][i1].minusEquals(1);
            }
        }
        PRINTMAT(laplacian);
        boolean hasEdgesToNowhere = laplacian[nVerts][nVerts].i.signum() != 0;
        PRINT(hasEdgesToNowhere);

        // Must do this one first. since detDestructiveBigInt really does destroy the contents
        double detDouble = detNonDestructiveDouble(hasEdgesToNowhere ? nVerts : nVerts-1,
                                                   laplacian); // all but last nontrivial row&column
        PRINT(detDouble);
        assert_ge(detDouble, 0);

        BigInt detBigInt = detDestructiveBigInt(
            hasEdgesToNowhere ? nVerts : nVerts-1,
            laplacian);
        PRINT(detBigInt);
        PRINT(detBigInt.doubleValue());
        PRINT(detDouble);
        assert_ge(detBigInt.signum(), 0);
        assert_almost_eq_rel(detBigInt.doubleValue(), detDouble, 1e-12);
        OUT("    out countSpanningTrees, returning "+detBigInt);
        return detBigInt;
    } // countSpanningTrees

    // TODO: this paper: https://pdfs.semanticscholar.org/208b/71b285804d96897731d41f9a4079d0523068.pdf
    // says "Colbourn et al. in [9] have proposed an algorithm which runs in O(n^2) time for an n-vertex planar graph!"
    // The Colbourn paper is:
    //  C.J. Colbourn, J.S. Provan, and D. Vertigan: A new approach to solving three combinatorial enumeration problems on planar graphs. Discrete Appl. Math. 60, 119–129 (1995)
    // Cool, found it here: http://www.sciencedirect.com/science/article/pii/0166218X95E01113
    // So let's code it up!
    // Oh argh, does it not use integer arithmetic?  I'm afraid this will blow up immensely.
    // Ah I see, they claim O(n log n) digits accuracy is sufficient.  Hmm.
    //
    // Okay how do I guide the search?
    // Can't seem to find any of the papers that show how to reduce any planar graph
    // in O(n^2) operations, but there is this: https://en.wikipedia.org/wiki/Y-%CE%94_transform
    // which gives some clues...
    // Oh wait!  Check out http://www.wikiwand.com/en/Steinitz's_theorem .
    // It says any convex polyhedron can be transformed to a tetrahedron
    // by delta-Y and Y-deltas?
    public static void messAroundWithDeltaWye(Mesh originalMesh)
    {
        int verboseLevel = 2;
        if (verboseLevel >= 1) OUT("    in messAroundWithDeltaWye");
        if (verboseLevel >= 3) OUT("      originalMesh = "+originalMesh);
        if (false) originalMesh.sanityCheckTopology(); // XXX woops! dual mesh flunks because of the null endpoints!
        Mesh mesh = new Mesh(originalMesh);
        if (verboseLevel >= 3) OUT("      mesh = "+mesh);
        if (false) mesh.sanityCheckTopology(); // XXX woops! dual mesh flunks because of the null endpoints!

        // Hack-- get rid of that nonexistent vertex.
        // (CBB: should something like this be in Mesh?)
        {
            int nEdges = mesh.edges.size();
            boolean hasInfiniteVertex = false;
            FORI (iEdge, nEdges)
                if (mesh.getEdge(iEdge).initialVertex() == null)
                {
                    hasInfiniteVertex = true;
                    break;
                }
            if (hasInfiniteVertex)
            {
                Mesh.Vertex vert = mesh.newVertex(0.,0.,0.,0.); // meaningless
                FORI (iEdge, nEdges)
                {
                    Mesh.Edge edge = mesh.getEdge(iEdge);
                    if (edge.initialVertex() == null)
                        edge.setInitialVertex(vert);
                }
                if (verboseLevel >= 3) OUT("      after fixing: mesh = "+mesh);
            }
            FORI (iEdge, nEdges)
            {
                assert_ne(mesh.getEdge(iEdge).initialVertex(), null);
                assert_ne(mesh.getEdge(iEdge).next(), null);
            }
        }
        mesh.sanityCheckTopology(); // finally it's sane

        while (true)
        {
            if (verboseLevel >= 2) OUT("      top of loop: nVerts="+mesh.verts.size()+" nEdges="+mesh.edges.size());
            // Always go from simpler to more complicated,
            // so that we don't get confused, e.g. a pendant satisfies condition of a series
            // reduction.

            // loop deletion
            {
                if (verboseLevel >= 2) OUT("          checking for loops...");
                Mesh.Edge loop = null;
                {
                    int nEdges = mesh.edges.size();
                    FORI (iEdge, nEdges)
                    {
                        Mesh.Edge edge = mesh.getEdge(iEdge);
                        if (edge.initialVertex() == edge.finalVertex())
                        {
                            loop = edge;
                            break;
                        }
                    }
                }
                if (loop != null)
                {
                    if (verboseLevel >= 2) OUT("              found a loop! deleting it");
                    mesh.deleteEdge(loop);
                    continue;
                }
            }

            // pendant edge deletion
            {
                if (verboseLevel >= 2) OUT("          checking for pendants...");
                Mesh.Edge pendant = null;
                {
                    int nEdges = mesh.edges.size();
                    FORI (iEdge, nEdges)
                    {
                        Mesh.Edge edge = mesh.getEdge(iEdge);
                        Mesh.Edge nextEdge = edge.next();
                        assert_ne(nextEdge, edge); // since no loops
                        assert_eq(nextEdge==edge.opposite(),
                                  edge.finalVertex().arity == 1);
                        if (edge.finalVertex().arity == 1)
                        {
                            pendant = edge;
                            break;
                        }
                    }
                }
                if (pendant != null)
                {
                    if (verboseLevel >= 2) OUT("              found a pendant! deleting it");
                    Mesh.Vertex vert = pendant.finalVertex();
                    // just deleting the vert would do it, but deleting the edge first
                    // is potentially more efficient
                    assert_eq(vert.arity, 1);
                    mesh.deleteEdge(pendant);
                    assert_eq(vert.arity, 0);
                    mesh.deleteVertex(vert, null, null);
                    continue;
                }
            }
            // parallel reduction
            {
                if (verboseLevel >= 2) OUT("          checking for parallels...");
                Mesh.Edge parallel = null;
                {
                    int nEdges = mesh.edges.size();
                    FORI (iEdge, nEdges)
                    {
                        Mesh.Edge edge = mesh.getEdge(iEdge);
                        Mesh.Edge nextEdge = edge.next();
                        assert_ne(nextEdge, edge); // since no loops
                        assert_ne(nextEdge, edge.opposite()); // since no pendants
                        if (nextEdge.finalVertex() == edge.initialVertex())
                        {
                            parallel = edge;
                            break;
                        }
                    }
                }
                if (parallel != null)
                {
                    if (verboseLevel >= 2) OUT("              found a parallel! "+parallel+" deleting it");
                    mesh.deleteEdge(parallel);
                    continue;
                }
            }
            // series reduction
            {
                if (verboseLevel >= 2) OUT("          checking for serieses...");
                Mesh.Edge seriesStart = null;
                {
                    int nEdges = mesh.edges.size();
                    FORI (iEdge, nEdges)
                    {
                        Mesh.Edge edge = mesh.getEdge(iEdge);
                        Mesh.Edge nextEdge = edge.next();
                        assert_ne(nextEdge, edge); // since no loops
                        assert_ne(nextEdge, edge.opposite()); // since no pendants
                        assert_ne(nextEdge.finalVertex(), edge.initialVertex()); // since no parallels
                        assert_eq(edge.next().opposite().next().opposite()==edge,
                                  edge.finalVertex().arity == 2);
                        if (edge.finalVertex().arity == 2)
                        {
                            seriesStart = edge;
                            break;
                        }
                    }
                }
                if (seriesStart != null)
                {
                    if (verboseLevel >= 2) OUT("              found a series! deleting it");

                    if (verboseLevel >= 3) OUT("                  before: "+mesh);

                    // create a replacement edge,
                    // then delete the two originals and the vertex.
                    mesh.sanityCheckTopology();
                    Mesh.Edge shortCut = mesh.newEdge(true);
                    // can't call sanityCheckTopology again until after connected both endpoints
                    // see picture at insertEdgeBefore
                    assert_eq(shortCut.prev(), shortCut.opposite());
                    mesh.insertEdgeBefore(shortCut, seriesStart);
                    assert_ne(shortCut.prev(), shortCut.opposite());
                    assert_eq(shortCut.opposite().prev(), shortCut);
                    mesh.insertEdgeBefore(shortCut.opposite(), seriesStart.next().next());
                    mesh.sanityCheckTopology();
                    Mesh.Vertex vert = seriesStart.finalVertex();
                    assert_eq(vert.arity, 2);
                    mesh.deleteEdge(seriesStart.next());
                    assert_eq(vert.arity, 1);
                    mesh.deleteEdge(seriesStart);
                    assert_eq(vert.arity, 0);
                    mesh.deleteVertex(vert, null, null);
                    mesh.sanityCheckTopology();

                    if (verboseLevel >= 3) OUT("                  after: "+mesh);
                    continue;
                }
            }
            // wye-delta transformation
            {
                if (verboseLevel >= 2) OUT("          checking for wyes...");
                Mesh.Edge towardsWye = null;
                {
                    int nEdges = mesh.edges.size();
                    FORI (iEdge, nEdges)
                    {
                        Mesh.Edge edge = mesh.getEdge(iEdge);
                        assert_eq(edge.next().opposite().next().opposite().next().opposite()==edge,
                                  edge.finalVertex().arity == 3);
                        if (edge.finalVertex().arity == 3)
                        {
                            towardsWye = edge;
                            break;
                        }
                    }
                }
                if (towardsWye != null)
                {
                    if (verboseLevel >= 2) OUT("              found a wye! changing it to a delta");
                    Mesh.Edge A = towardsWye;
                    Mesh.Edge B = A.next().opposite();
                    Mesh.Edge C = B.next().opposite();
                    assert_eq(A, C.next().opposite());
                    Mesh.Edge AB = mesh.newEdge(true);
                    Mesh.Edge BC = mesh.newEdge(true);
                    Mesh.Edge CA = mesh.newEdge(true);
                    mesh.insertEdgeBefore(AB, A);
                    mesh.insertEdgeBefore(BC, B);
                    mesh.insertEdgeBefore(CA, C);
                    mesh.insertEdgeBefore(AB.opposite(), B.opposite().next());
                    mesh.insertEdgeBefore(BC.opposite(), C.opposite().next());
                    mesh.insertEdgeBefore(CA.opposite(), A.opposite().next());

                    mesh.sanityCheckTopology();
                    Mesh.Vertex vert = A.finalVertex();
                    assert_eq(vert.arity, 3);
                    mesh.deleteEdge(A);
                    assert_eq(vert.arity, 2);
                    mesh.deleteEdge(B);
                    assert_eq(vert.arity, 1);
                    mesh.deleteEdge(C);
                    assert_eq(vert.arity, 0);
                    mesh.deleteVertex(vert, null, null);
                    mesh.sanityCheckTopology();

                    continue;
                }
            }
            break; // didn't find any of the constructs
        }
        if (verboseLevel >= 1) OUT("    out messAroundWithDeltaWye");
    } // messAroundWithDeltaWye


    // Simpler mesh data structure, suitable for running
    // the algorithm from David Bruce Wilson
    // "Generating Random Spanning Trees More Quickly than the Cover Time".
    //
    // Subtleties:
    //     - Depending on how original mesh was constructed,
    //       it might have edges leading nowhere or coming from nowhere.
    //       The "nowhere" gets made into a vertex (the "infinite vertex").
    //     - We might or might not want to consider all inside-out vertices
    //       (i.e. those with weight < 0) to be part of the infinite vertex.
    //       This is a param to the constructor.
    public static class SimplerMeshDataStructure
    {
        public int e2v[/*nEdges*/][/*2*/]; // edge to verts
        public int v2e[/*nVerts*/][]; // vert to edges out

        public SimplerMeshDataStructure(Mesh mesh, boolean mergeInsideOutVertsIntoInfiniteVert)
        {
            int nVerts = mesh.verts.size(); // may add 1 though
            int nEdges = mesh.edges.size();
            this.e2v = new int[nEdges][2];

            int e2next[] = new int[nEdges];
            boolean infiniteVertUsed = false; // until proven otherwise
            FORI (iEdge, nEdges)
            {
                Mesh.Edge edge = mesh.getEdge(iEdge);
                assert_eq(edge.myIndex(), iEdge);
                assert_eq(edge.opposite().myIndex(), (iEdge^1));
                Mesh.Vertex v0 = edge.initialVertex();
                Mesh.Vertex v1 = edge.finalVertex();
                if (v0 == null || v1 == null)
                    infiniteVertUsed = true;
                int i0 = v0==null ? nVerts : v0.myIndex();
                int i1 = v1==null ? nVerts : v1.myIndex();
                e2v[iEdge][0] = i0;
                e2v[iEdge][1] = i1;
                Mesh.Edge next = edge.next();
                if (next == null)
                {
                    // final vertex is the infinite one; to find next, need to walk backwards around the face
                    next = edge;
                    while (next.prev() != null)
                        next = next.prev();
                }
                e2next[iEdge] = next.myIndex();
            }
            if (mergeInsideOutVertsIntoInfiniteVert)
            {
                boolean isInsideOut[] = new boolean[nVerts+1];
                FORI (iVert, nVerts)
                    isInsideOut[iVert] = (mesh.getVert(iVert).weight < 0);
                isInsideOut[nVerts] = true; // the infinite one, if any
                //PRINTVEC(isInsideOut);
                FORI (iEdge, nEdges)
                    FORI (iVertThisEdge, 2)
                    {
                        if (isInsideOut[e2v[iEdge][iVertThisEdge]])
                        {
                            e2v[iEdge][iVertThisEdge] = nVerts;
                            infiniteVertUsed = true;
                        }
                    }
                // Note that it may be that some original verts are now unused in e2v
            }
            if (infiniteVertUsed)
                nVerts++;
            this.v2e = new int[nVerts][];
            {
                int arities[] = new int[nVerts]; // zeros initially
                FORI (iEdge, nEdges)
                    arities[e2v[iEdge][0]]++;
                FORI (iVert, nVerts)
                {
                    v2e[iVert] = new int[arities[iVert]];
                    arities[iVert] = 0;
                }
                if (false)
                {
                    // Simple way, edges don't come out in any particular order.
                    FORI (iEdge, nEdges)
                    {
                        int iVert = e2v[iEdge][0];
                        v2e[iVert][arities[iVert]++] = iEdge;
                    }
                }
                else
                {
                    // Edges come out in order, following the mesh's ->opp->next pointers.
                    // I.e. CCW if next pointers go CW around face,
                    // and vice versa.
                    // CBB: I don't think I really need this bit array; could instead just clear
                    // entries in e2next or something.  But that would be more complicated.
                    boolean edgeDone[] = new boolean[nEdges]; // all false initially
                    FORI(iEdge0, nEdges)
                    {
                        for (int iEdge = iEdge0; !edgeDone[iEdge]; iEdge = e2next[iEdge^1])
                        {
                            edgeDone[iEdge] = true;
                            int iVert = e2v[iEdge][0];
                            v2e[iVert][arities[iVert]++] = iEdge;
                        }
                    }
                }
                // sanity check
                FORI (iVert, nVerts)
                {
                    assert_eq(v2e[iVert].length, arities[iVert]);
                    FORI (iEdgeOut, v2e[iVert].length)
                        assert_eq(e2v[v2e[iVert][iEdgeOut]][0], iVert);
                }
            }
        } // SimplerMeshDataStructure ctor

        public boolean isConnectedExceptMaybeForIsolatedVerts()
        {
            // DFS is actually faster supposedly but whatever
            int nVerts = v2e.length;
            int nEdges = e2v.length;
            MergeFind mergeFind = new MergeFind(nVerts);
            FORI (iEdge, nEdges)
            {
                int iVert = e2v[iEdge][0];
                int jVert = e2v[iEdge][1];
                mergeFind.merge(iVert, jVert);
            }
            int found = -1;
            FORI (iVert, nVerts)
            {
                if (v2e[iVert].length == 0) continue; // vertex got removed (or was isolated)
                if (found == -1)
                    found = mergeFind.find(iVert);
                else if (mergeFind.find(iVert) != found)
                    return false;
            }
            return true;
        } // isConnectedExceptMaybeForIsolatedVerts

        // Do not call this unless connected! (in the sense that isConnectedExceptMaybeForIsolatedVerts returns).
        public boolean[/*nEdges/2*/] randomSpanningTree(java.util.Random generator)
        {
            if (e2v.length == 0)
                return new boolean[0];
            // Use uniform random spanning tree algorithm, from David Bruce Wilson
            // "Generating Random Spanning Trees More Quickly than the Cover Time"
            // Must start with random vertex of random edge.
            int r = e2v[generator.nextInt(e2v.length)][generator.nextInt(2)];
            int nVerts = v2e.length;
            boolean inTree[] = new boolean[nVerts]; // false initially
            int theEdgeOut[] = new int[nVerts];
            theEdgeOut[r] = -1;
            inTree[r] = true;
            FORI (iVert, nVerts)
            {
                if (v2e[iVert].length == 0)
                    continue; // the vertex got removed (probably merged into the infinite vertex)
                for (int u = iVert; !inTree[u]; u = e2v[theEdgeOut[u]][1])
                    theEdgeOut[u] = v2e[u][generator.nextInt(v2e[u].length)];
                for (int u = iVert; !inTree[u]; u = e2v[theEdgeOut[u]][1])
                    inTree[u] = true;
            }
            boolean answer[] = new boolean[e2v.length/2]; // all false initially
            FORI (iVert, nVerts)
            {
                if (v2e[iVert].length == 0)
                    continue; // the vertex got removed (probably merged into the infinite vertex)
                int iEdge = theEdgeOut[iVert];
                assert_eq((iEdge == -1), (iVert==r));
                if (iEdge != -1)
                {
                    assert_eq(e2v[iEdge][0], iVert);
                    answer[iEdge/2] = true;
                }
            }
            return answer;
        } // randomSpanningTree

        // Given a spanning tree, expressed in undirectedEdgeIsInSpanningTree
        // (as returned by randomSpanningTree()), and a root,
        // figure out each vertex's "parent" edge, i.e. the edge pointing towards the root.
        public int[] getVertToParentEdgeOut(int root,
                                            boolean undirectedEdgeIsInSpanningTree[/*nUndirectedEdges*/])
        {
            int verboseLevel = 0;
            if (verboseLevel >= 1) System.out.println("in getVertToParentEdgeOut");
            // TODO: BUG: VecMath.toString messes up on int[][], it omits final closing brace
            if (verboseLevel >= 1) System.out.println("  e2v = "+VecMath.toString(e2v));
            if (verboseLevel >= 1) System.out.println("  v2e = "+VecMath.toString(v2e));
            if (verboseLevel >= 1) System.out.println("  undirectedEdgeIsInSpanningTree = "+VecMath.toString(undirectedEdgeIsInSpanningTree));
            int nVerts = this.v2e.length;
            int vertToParentEdgeOut[] = VecMath.fillvec(nVerts, -1);
            int queue[] = new int[nVerts];
            int queueSize = 0;
            queue[queueSize++] = root;
            while (queueSize > 0)
            {
                int iVert = queue[--queueSize];
                int edgesOut[] = this.v2e[iVert];
                FORI (iEdgeOut, edgesOut.length)
                {
                    int iEdge = edgesOut[iEdgeOut];
                    if (iEdge != vertToParentEdgeOut[iVert] // i.e. if didn't just come from there
                     && undirectedEdgeIsInSpanningTree[iEdge/2])
                    {
                        assert_eq(this.e2v[iEdge][0], iVert);
                        int jVert = this.e2v[iEdge][1];
                        int parentEdgeOut = iEdge ^ 1; // opposite edge, i.e. the edge from jVert to iVert
                        vertToParentEdgeOut[jVert] = parentEdgeOut;
                        assert_eq(this.e2v[parentEdgeOut][0], jVert);
                        assert_eq(this.e2v[parentEdgeOut][1], iVert);
                        queue[queueSize++] = jVert;
                    }
                }
            }
            if (verboseLevel >= 1) System.out.println("  vertToParentEdgeOut = "+Arrays.toStringCompact(vertToParentEdgeOut));
            if (verboseLevel >= 1) System.out.println("out getVertToParentEdgeOut");
            return vertToParentEdgeOut;
        } // getVertToParent
    } // SimplerMeshDataStructure

    // See paper "Generating Random Spanning Trees
    // More Quickly than the Cover Time" by David Bruce Wilson.
    // But, can't I do it in O(n) time,
    // by simply growing the tree and picking a random new edge out of it on every step?
    // (answer: no, the next edge out of the spanning tree can't be picked uniformly)
    // Verify that Wilson's algorithm gives something uniformly random,
    // or that the more well known random walk one does,
    // or that a similar one doesn't.
    // Note: This doesn't really do anything useful, it just prints stats, with method
    // chosen via hard-coded true/false's in the code below.
    public static void analyzeRandomSpanningTrees(Mesh mesh)
    {
        System.out.println("    in analyzeRandomSpanningTrees");
        int nEdges = mesh.edges.size();
        PRINT(nEdges);
        if (nEdges > 26) // i.e. 13 undirected.  (takes too long otherwise)
        {
            System.out.println("      too many edges, bailing");
            System.out.println("    out analyzeRandomSpanningTrees");
            return;
        }

        SimplerMeshDataStructure simplerMeshDataStructure = new SimplerMeshDataStructure(mesh, true);
        if (!simplerMeshDataStructure.isConnectedExceptMaybeForIsolatedVerts())
        {
            System.out.println("      graph is disconnected; bailing");
            System.out.println("    out analyzeRandomSpanningTrees");
            return;
        }

        java.util.Random generator = new java.util.Random();

        int counts[] = new int[1<<nEdges];

        int nTries = 1000*1000;
        FORI (iTry, nTries)
        {
            // Make a random spanning tree, and increment its count.

            int whichTree;

            if (true)
            {
                // Wilson's algorithm.
                boolean answer[] = simplerMeshDataStructure.randomSpanningTree(generator);
                whichTree = 0;
                FORI (iUndirectedEdge, answer.length)
                    if (answer[iUndirectedEdge])
                    {
                        assert_lt(iUndirectedEdge, 32);
                        whichTree |= (1 << iUndirectedEdge);
                    }
            }
            else if (false)
            {
                // random walk from 0,
                // keeping *last* edge to each new vertex.
                // This apparently isn't uniform!

                int e2v[][] = simplerMeshDataStructure.e2v;
                int v2e[][] = simplerMeshDataStructure.v2e;
                int nVerts = v2e.length; // may be 1 more than mesh.verts.size(). CBB: error prone!

                boolean inTree[] = new boolean[nVerts]; // false initially
                int prev[] = VecMath.fillvec(nVerts, -1); // vertex to prev *edge*, not vertex
                int r = 0; // arbitrarily

                inTree[r] = true;
                int nVertsInTree = 1;
                int u = r;
                while (nVertsInTree < nVerts)
                {
                    int iEdge = v2e[u][generator.nextInt(v2e[u].length)];
                    u = e2v[iEdge][1];
                    prev[u] = iEdge; // clobber old value if any, so we retain last edge to u
                    if (!inTree[u])
                    {
                        inTree[u] = true;
                        nVertsInTree++;
                    }
                }

                whichTree = 0;
                FORI (iVert, nVerts)
                {
                    int iEdge = prev[iVert];
                    if (iEdge != -1)
                    {
                        whichTree |= (1 << (iEdge/2));
                    }
                }
            }
            else if (false)
            {
                // random walk from 0,
                // keeping *first* edge to each new vertex.
                // This seems to be uniform.
                // (and takes cover time, I think?)

                int e2v[][] = simplerMeshDataStructure.e2v;
                int v2e[][] = simplerMeshDataStructure.v2e;
                int nVerts = v2e.length; // may be 1 more than mesh.verts.size(). CBB: error prone!

                boolean inTree[] = new boolean[nVerts]; // false initially
                int prev[] = VecMath.fillvec(nVerts, -1); // vertex to prev *edge*, not vertex
                int r = 0; // arbitrarily

                inTree[r] = true;
                int nVertsInTree = 1;
                int u = r;
                while (nVertsInTree < nVerts)
                {
                    int iEdge = v2e[u][generator.nextInt(v2e[u].length)];
                    u = e2v[iEdge][1];
                    if (!inTree[u])
                    {
                        prev[u] = iEdge; // only record first edge to u
                        inTree[u] = true;
                        nVertsInTree++;
                    }
                }

                whichTree = 0;
                FORI (iVert, nVerts)
                {
                    int iEdge = prev[iVert];
                    if (iEdge != -1)
                    {
                        whichTree |= (1 << (iEdge/2));
                    }
                }
            }
            else
            {
                assert(false);
            }

            //PRINT(whichTree);

            counts[whichTree]++;
        }
        //PRINTARRAY(counts);

        SortStuff.sort(counts);
        int nZeros = 0;
        while (nZeros < counts.length && counts[nZeros] == 0)
            nZeros++;
        counts = (int[])Arrays.subarray(counts, nZeros, counts.length-nZeros);
        PRINTARRAY(counts);
        PRINT(counts.length);

        System.out.println("    out analyzeRandomSpanningTrees");
    } // analyzeRandomSpanningTrees


    /*
        What about enumerating all spanning trees?
        References:
          http://www.hariharan-ramesh.com/papers/spantree1.pdf
            "Algorithms for Enumerating All Spanning Trees of Undirected and Weighted Graphs"
              By Sanjiv Kapoor, H. Ramesh
            Sounds like it has a particularly nice form of output (1-edge diffs between each tree and next)

          https://en.wikipedia.org/wiki/Kirchhoff's_theorem#Explicit_enumeration_of_spanning_trees
            do the determinant algorithm on intederminates; resulting polynomial's monomials are the possible
            spanning trees

          http://www.scielo.br/scielo.php?script=sci_arttext&pid=S0101-74382005000200004
            "An algorithm to generate all spanning trees of a graph in order of increasing cost"
              by Kenneth Sörensen; Gerrit K. Janssens

          http://www.cs.colorado.edu/department/publications/reports/docs/CU-CS-103-77.pdf
            "Finding All Spanning Trees of Undirected and Directed Graphs"
              by Harold N. Gabow

          http://www.cs.ou.edu/~thulasi/Algorithm/Complexity%20of%20Computation%20of%20a%20Spanning%20Tree%20Enumeration%20Algorithm.pdf
            "Complexity of Computation of a Spanning Tree Enumeration Algorithm"
              by R. JAYAKUMAR, K. THULASIRAMAN, AND M. N. S. SWAMY

          http://math.mit.edu/~apost/papers/tree.pdf
            "ENUMERATION OF SPANNING TREES OF GRAPHS"
              by Igor Pak, Alexander Postnikov

    */
    /*
        I'm going to use Algorithm 2 in Kapoor/Ramesh's paper,
        and I can use the following simplifying assumptions:
          - the graph is biconnected (i.e. no cut vertices), so decomposition into biconnected components is unnecessary
    */

#ifdef NOTYET
    private static void enumerateAllSpanningTreesSmartWorkInProgress(int v2e[/*nVerts*/][/*2*/], int e2v[/*nEdges*/][])
    {
        // "The data structure will store the current spanning tree in the form of a parent pointer
        // and list of child pointers for each node, with only edges not currently in the IN set present."
        // I think maybe each child list should be a doubly linked list, for O(1) combining.
        // 1. find a dfs spanning tree, for the root node of the computation tree.
        class DFSVert
        {
            public DFSVert(int iVert)
            {
                this.iVert = iVert;
            }
            int iVert;
            DFSVert parent = null;
            DFSVert firstChild = null;
            DFSVert nextSibling = null;
            boolean selfToFirstChildIsBackEdge;
            boolean parentToNextSiblingIsBackEdge;
        }
        int nVerts = v2e.length;
        int nEdges = e2v.length;
        DFSVert dfsVerts[] = new DFSVert[nVerts];
        {
            FORI (iVert, nVerts)
                dfsVerts[iVert] = new DFSVert(iVert);
            FORI (iVert, nVerts)
            {
                FORIDOWN (iChild, v2e[iVert].length)
                {
                    int edge[/*2*/] = e2v[v2e[iVert][iChild]];
                    assert_eq(edge[0], iVert);
                    int jVert = edge[1];
                    dfsVerts[jVert].parent = dfsVerts[iVert];
                    dfsVerts[jVert].nextSibling = dfsVerts[iVert].firstChild;
                    dfsVerts[iVert].firstChild = dfsVerts[iVert];
                }
            }
        }

        static void dfs(DFSVert dfsVert)
        {
            for (DFSVert child = dfsVert.firstChild;
                 child != null;
                 child = child.nextSibling)
            {
                if (child.seen)
                {
                    if (child == dfsVert.firstChild)
                        dfsVert.selfToFirstChildIsBackEdge = true;
                    else
                        previous.parentToNextSiblingIsBackEdge = true;
                }
                else
                {
                }
            }
        }
        boolean v2seen[] = new boolean[nVerts]; // all false initially
        boolean e2isInTree[] = new int[nEdges];
        boolean e2isBack[] = new int[nEdges];

        static void dfs(int v2e[][], int e2v[][],
                        boolean v2seen[], int e2isBack[],
                        int iVert)
        {
            assert(!v2seen[iVert]);
            v2seen[iVert] = true;
            FORI (iChild, v2e[iVert].length)
            {
                int iEdge = v2e[iVert][iChild];
                assert_eq(e2v[iEdge][0], iVert);
                int jVert = e2v[iEdge][1];
                if (v2seen[jVert])
                    e2isBack[iEdge] = true;
                else
                {
                    v2parent[jVert] = iVert;
                    dfs(v2e, e2v, v2seen, e2isBack, jVert);
                }
            }
        }
        FORI (iVert, nVerts)
            if (!v2seen[iVert])
                dfs(v2e, e2v, v2seen, e2isBack, iVert);

        /*
        static void dfs(int iVert, int v2e[][], int e2v[][], DFSVert dfsVerts[])
        {
            DFSVert lastChild = null;
            FORIDOWN (iChild, v2e[iVert].length)
            {
                assert_eq(v2e[iVert][iChild][0], iVert);
                int jVert = v2e[iVert][iChild][1];
                dfsVerts[jVert].nextSibling = dfsVerts[iVert].firstChild;
                dfsVerts[iVert].firstChild = dfsVerts[iVert];
            }
            FORI (iChild, v2e[iVert].length)
            {
                dfsVerts[iVert].
            }
        }
        */

    } // enumerateAllSpanningTrees
#endif // NOTYET

    // http://stackoverflow.com/questions/1235179/simple-way-to-repeat-a-string-in-java/4903603#answer-4903603
    private static String repeat(String s, int n) { return new String(new char[n]).replace("\0", s); }

    // Just to hold stuff for recursion used by enumerateAllSpanningTreesDumb
    public interface enumerateAllSpanningTreesDumbCallback
    {
        boolean run(IntArrayList edgeIndices); // return true iff should continue
    }
        private static class enumerateAllSpanningTreesDumbHelper
        {
            private int nVerts;
            private int e2v[][];
            private int nFaces;
            private int e2f[][];
            enumerateAllSpanningTreesDumbCallback callback;
            ArrayList vertMergeFindStack;
            ArrayList faceMergeFindStack;
            IntArrayList edgeIndices;
            int verboseLevel;

            public enumerateAllSpanningTreesDumbHelper(
                int nVerts, int e2v[][],
                int nFaces, int e2f[][],
                enumerateAllSpanningTreesDumbCallback callback,
                ArrayList vertMergeFindStack,
                ArrayList faceMergeFindStack,
                IntArrayList edgeIndices,
                int verboseLevel)
            {
                assert_eq(e2v.length, e2f.length);
                this.nVerts = nVerts;
                this.e2v = e2v;
                this.nFaces = nFaces;
                this.e2f = e2f;
                this.callback = callback;
                this.vertMergeFindStack = vertMergeFindStack;
                this.faceMergeFindStack = faceMergeFindStack;
                this.edgeIndices = edgeIndices;
                this.verboseLevel = verboseLevel;
            }
            public boolean recurse(int iEdge)
            {
                int nEdges = e2v.length;
                if (verboseLevel >= 2) OUT(repeat("    ",iEdge/2)+"        in recurse(iEdge="+iEdge+"/"+nEdges+")");
                if (true)
                {
                    // This stuff just naturally works out, I guess...
                    // The fact that we don't allow cuts that form cycles
                    // means we can always extend the current cuts to a maximal cut tree,
                    // and the fact that we don't allow folds that form cycles of faces
                    // means we can always extend the current folds to form a maximal fold tree.
                    int nCutsTarget = nVerts - 1;
                    int minPossibleCuts = edgeIndices.size();
                    int maxPossibleCuts = edgeIndices.size() + (nEdges - iEdge);
                    assert_le(minPossibleCuts, nCutsTarget);
                    assert_le(nCutsTarget, maxPossibleCuts);
                }

                if (iEdge == nEdges)
                {
                    assert_eq(edgeIndices.size(), nVerts-1);
                    return callback.run(edgeIndices);
                }
                MergeFind vertMergeFind = (MergeFind)vertMergeFindStack.get(vertMergeFindStack.size()-1);
                MergeFind faceMergeFind = (MergeFind)faceMergeFindStack.get(faceMergeFindStack.size()-1);
                int iVert = e2v[iEdge][0];
                int jVert = e2v[iEdge][1];
                int iFace = e2f[iEdge][0];
                int jFace = e2f[iEdge][1];
                if (verboseLevel >= 2) OUT(repeat("    ",iEdge/2)+"          iVert="+iVert+" jVert="+jVert+" nVerts="+nVerts+"  iFace="+iFace+" jFace="+jFace+" nFaces="+nFaces);
                if (vertMergeFind.find(iVert) != vertMergeFind.find(jVert))
                {
                    // It's cuttable.
                    MergeFind newVertMergeFind = new MergeFind(vertMergeFind);
                    newVertMergeFind.merge(iVert, jVert);
                    vertMergeFindStack.add(newVertMergeFind); // push
                    edgeIndices.add(iEdge); // push
                    if (!recurse(iEdge+2)) // we only look at one direction of each edge
                    {
                        if (verboseLevel >= 2) OUT(repeat("    ",iEdge/2)+"        out recurse(iEdge="+iEdge+"/"+nEdges+"), returning false");
                        return false;
                    }
                    edgeIndices.removeIndex(edgeIndices.size()-1); // pop
                    vertMergeFindStack.remove(vertMergeFindStack.size()-1); // pop
                }
                if (faceMergeFind.find(iFace) != faceMergeFind.find(jFace))
                {
                    // It's foldable.
                    MergeFind newFaceMergeFind = new MergeFind(faceMergeFind);
                    newFaceMergeFind.merge(iFace, jFace);
                    faceMergeFindStack.add(newFaceMergeFind); // push
                    if (!recurse(iEdge+2)) // we only look at one direction of each edge
                    {
                        if (verboseLevel >= 2) OUT(repeat("    ",iEdge/2)+"        out recurse(iEdge="+iEdge+"/"+nEdges+"), returning false");
                        return false;
                    }
                    faceMergeFindStack.remove(faceMergeFindStack.size()-1); // pop
                }
                if (verboseLevel >= 2) OUT(repeat("    ",iEdge/2)+"        out recurse(iEdge="+iEdge+"/"+nEdges+"), returning true");
                return true;
            }
        } // private static class enumerateAllSpanningTreesDumbHelper

    // Assumption: *not* "Calc underside when delaunayizing".
    // Should assert-fail fairly early due to checking euler's formula, if not.
    public static boolean enumerateAllSpanningTreesDumb(
        Mesh mesh, Mesh dualMesh,  // typically backwards from caller... although it doesn't really matter, this algorithm is self dual
        enumerateAllSpanningTreesDumbCallback callback)
    {
        int verboseLevel = 1;
        if (verboseLevel >= 1) OUT("    in enumerateAllSpanningTreesDumb");
        long t0millis = System.currentTimeMillis();

        int e2v[][] = new SimplerMeshDataStructure(mesh, true).e2v; // assumes infinite vert was omitted
        int e2f[][] = new SimplerMeshDataStructure(dualMesh, false).e2v; // assumes there's no missing inside out face
        int nEdges = e2v.length;
        assert_eq(nEdges, e2f.length);
        assert_eq(nEdges%2, 0); // directed edges
        int nVerts = mesh.verts.size() + 1;
        int nFaces = dualMesh.verts.size();
        // Check euler's formula, so we don't go down a rabbit hole if they gave us a bad mesh
        assert_eq(nVerts+nFaces, nEdges/2 + 2);

        if (verboseLevel >= 1) OUT("      nVerts = "+nVerts);
        if (verboseLevel >= 1) OUT("      nFaces = "+nFaces);
        if (verboseLevel >= 1) OUT("      nEdges = "+nEdges+" = 2*"+(nEdges/2));

        ArrayList/*<MergeFind>*/ vertMergeFindStack = new ArrayList(); vertMergeFindStack.add(new MergeFind(nVerts));
        ArrayList/*<MergeFind>*/ faceMergeFindStack = new ArrayList(); faceMergeFindStack.add(new MergeFind(nFaces));
        IntArrayList edgeIndices = new IntArrayList();
        enumerateAllSpanningTreesDumbHelper helper = new enumerateAllSpanningTreesDumbHelper(
            nVerts, e2v,
            nFaces, e2f,
            callback,
            vertMergeFindStack,
            faceMergeFindStack,
            edgeIndices,
            verboseLevel);
        boolean finished = helper.recurse(0);
        long t1millis = System.currentTimeMillis();
        if (verboseLevel >= 1) OUT("    out enumerateAllSpanningTreesDumb, returning finished="+finished+" in "+(t1millis-t0millis)/1000.+" secs");
        return finished;
    } // enumerateAllSpanningTreesDumb


    // I seem to have set the bar too high on using VecMath for this... make private utility function instead
    private static double[] v3xm44(double v[/*3*/], double m[/*4*/][/*4*/])
    {
        int three = v.length;
        assert_eq(m.length, three+1);
        assert_eq(m[0].length, three+1);
        double scratch[] = Arrays.append(v, 1.);
        scratch = VecMath.vxm(scratch, m);
        if (scratch[three] == 1.)
            return (double[])Arrays.subarray(scratch, 0, three);
        else
            return VecMath.vxs(three, scratch, scratch[three]);
    }

    public static Mesh.Vertex[] findAllVertsThatAreImages(Mesh mesh, double v[/*2*/], double group[][/*2*/][/*2*/], double tol)
    {
        int nVerts = mesh.verts.size();
        boolean foundVert[] = new boolean[nVerts];
        int nFound = 0;
        FORI (iGroup, group.length)
        {
            assert_eq(v.length, 3);
            double image[] = v3xm44(v,group[iGroup]);
            assert_eq(image.length, 3);
            FORI (iVert, nVerts)
            {
                if (!foundVert[iVert])
                {
                    Mesh.Vertex vertI = mesh.getVert(iVert);
                    // TODO: compute in homo
                    if (EQ(image[0], vertI.x(), tol)
                     && EQ(image[1], vertI.y(), tol)
                     && EQ(image[2], vertI.z(), tol))
                    {
                        foundVert[iVert] = true;
                        nFound++;
                    }
                }
            }
        }
        Mesh.Vertex answer[] = new Mesh.Vertex[nFound];
        nFound = 0;
        FORI (iVert, nVerts)
            if (foundVert[iVert])
                answer[nFound++] = mesh.getVert(iVert);
        assert_eq(nFound, answer.length);
        return answer;
    } // findAllVertsThatAreImages

    // TODO: move these to VecMath I think
    // Normalize so max abs value of coordinates is 1.
    private static void homoNormalize(int n, double answer[], double v[])
    {
        double divideByThis = ABS(v[0]);
        for (int i = 1; i < n; ++i) // skip 0
        {
            double absvi = ABS(v[i]);
            divideByThis = MAX(divideByThis, absvi);
        }
        VecMath.vxs(n, answer, v, 1./divideByThis);
    }
    private static void homoNormalize(double answer[], double v[])
    {
        homoNormalize(MIN(answer.length,v.length), answer, v);
    }
    private static double[] homoNormalize(double v[])
    {
        double answer[] = new double[v.length];
        homoNormalize(v.length, answer, v);
        return answer;
    }

    // Might or might not return the same mesh.
    public static Mesh forceMeshSymmetryByDeletingVertsDestructive(Mesh mesh, double group[][][], boolean retainConnectivity)
    {
        System.out.println("    in forceMeshSymmetryByDeletingVertsDestructive");
        int nVerts = mesh.verts.size();
        System.out.println("          nVerts = "+nVerts);
        double vertsHomo[][] = new double[nVerts][4];
        FORI (iVert, nVerts)
        {
            Mesh.Vertex vert = mesh.getVert(iVert);
            vertsHomo[iVert][0] = vert.X();
            vertsHomo[iVert][1] = vert.Y();
            vertsHomo[iVert][2] = vert.Z();
            vertsHomo[iVert][3] = vert.W();
        }

        // as recommended in FuzzyPointHashTable doc...
        FuzzyPointHashTable fuzzyTable = new FuzzyPointHashTable(1e-12, 1e-10, 1/1024.);
        Object dummy = new Object(); // we really want a hash set, not hash table, so need a dummy object, distinct from null

        // Initial pass adding originals, since those are the preferred images
        FORI (iVert, nVerts)
        {
            if (fuzzyTable.put(homoNormalize(vertsHomo[iVert]),dummy) == null) // i.e. if it wasn't already there
            {
                // nothing. we don't dedup here (although maybe we should).
            }
        }
        // Retain only verts in vertsHomo that are "all there".
        // CBB: probably theres a more efficient algorithm; whatever
        boolean bad[] = new boolean[nVerts];
        int nBad = 0;
        {
            double scratchHomo[] = new double[4];
            double scratchHomoNormalized[] = new double[4];
            FORI (iVert, nVerts)
            {
                for (int iSymmetry = 1; iSymmetry < group.length; ++iSymmetry) // skip 0 since we did it already
                {
                    VecMath.vxm(scratchHomo, vertsHomo[iVert], group[iSymmetry]);
                    homoNormalize(scratchHomoNormalized, scratchHomo);
                    if (fuzzyTable.get(scratchHomoNormalized) == null)
                    {
                        bad[iVert] = true;
                        nBad++;
                        break;
                    }
                }
            }
        }
        if (nBad == 0)
        {
            System.out.println("    out forceMeshSymmetryByDeletingVertsDestructive (nothing changed in "+nVerts+" verts)");
            return mesh;
        }
        if (retainConnectivity)
        {
            // Note, each removal takes O(n) time, so this is quadratic.
            FORIDOWN(iVert, nVerts) // backwards so that deleting won't mess up indices of future work
            {
                if (bad[iVert])
                {
                    mesh.deleteVertex(mesh.getVert(iVert), null, null);
                }
            }
            System.out.println("    out forceMeshSymmetryByDeletingVertsDestructive (deleted "+nBad+"/"+nVerts+" verts in place))");
            return mesh;
        }
        else
        {
            double goodVerts[][] = new double[nVerts-nBad][];
            int nGood = 0;
            FORI (iVert, nVerts)
                if (!bad[iVert])
                    goodVerts[nGood++] = vertsHomo[iVert];
            assert_eq(nGood, goodVerts.length);
            Mesh answer = new Mesh(goodVerts, new int[0][]);
            System.out.println("    out forceMeshSymmetryByDeletingVertsDestructive (created new mesh to delete "+nBad+"/"+nVerts+" verts)");
            return answer;
        }
    } // forceMeshSymmetryByDeletingVertsDestructive

    // Currently destroys connectivity. Another option would be to add verts one by one, the same as if user created them.
    // Currently removes dups.
    // CBB: should vert store notion of whether the intent was H or W?  we assume W.
    // NOTE: I'm using normalized homogeneous coords as keys... however, the reason I'm doing that is because I thought it would fix the behavior on "crack goes in spiral small", but it doesn't!  so maybe go back to using 3d points?  Not sure.  Normalized homo does have the advantage that it should do something reasonable with very large coords though.  Hmm.
    public static Mesh forceMeshSymmetryByReplicatingVerts(Mesh mesh, double group[][][])
    {
        System.out.println("    in forceMeshSymmetryByReplicatingVerts");
        int nVerts = mesh.verts.size();
        System.out.println("          nVerts = "+nVerts);
        double vertsHomo[][] = new double[nVerts][4];
        FORI (iVert, nVerts)
        {
            Mesh.Vertex vert = mesh.getVert(iVert);
            vertsHomo[iVert][0] = vert.X();
            vertsHomo[iVert][1] = vert.Y();
            vertsHomo[iVert][2] = vert.Z();
            vertsHomo[iVert][3] = vert.W();
        }

        // as recommended in FuzzyPointHashTable doc...
        FuzzyPointHashTable fuzzyTable = new FuzzyPointHashTable(1e-12, 1e-10, 1/1024.);
        Object dummy = new Object(); // we really want a hash set, not hash table, so need a dummy object, distinct from null

        ArrayList/*<double[]>*/ finalVertsArrayList = new ArrayList();

        // Initial pass adding originals, since those are the preferred images
        FORI (iVert, nVerts)
        {
            if (fuzzyTable.put(homoNormalize(vertsHomo[iVert]),dummy) == null) // i.e. if it wasn't already there
                finalVertsArrayList.add(vertsHomo[iVert]);
        }
        double scratchHomo[] = new double[4];
        FORI (iVert, nVerts)
        {
            for (int iSymmetry = 1; iSymmetry < group.length; ++iSymmetry) // skip 0 since we did it already
            {
                VecMath.vxm(scratchHomo, vertsHomo[iVert], group[iSymmetry]);
                if (fuzzyTable.put(homoNormalize(scratchHomo),dummy) == null) // i.e. if it wasn't already there
                    finalVertsArrayList.add(VecMath.copyvec(scratchHomo));
            }
        }
        if (finalVertsArrayList.size() == nVerts)
        {
            // Note, connectivity is destroyed otherwise... not sure what's right in general
            System.out.println("    out forceMeshSymmetryByReplicatingVerts (returning original mesh)");
            return mesh;
        }
        double finalVerts[][] = new double[finalVertsArrayList.size()][4];
        finalVertsArrayList.toArray(finalVerts);
        finalVertsArrayList = null;

        Mesh answer = new Mesh(finalVerts, new int[0][]);

        System.out.println("    out forceMeshSymmetryByReplicatingVerts");
        return answer;

    } // forceMeshSymmetryByReplicatingVerts

    public static Mesh changeMeshRotationalSymmetry(Mesh mesh,
                                                    int oldP, int oldQ,
                                                    int newP, int newQ)
    {
        System.out.println("    in changeMeshRotationalSymmetry");
        ArrayList/*<double[]>*/ newVertsArrayList = new ArrayList();

        if (oldQ == 1 && newQ == 1)
        {
            // Old and new fundamental regions are infinite pie slices
            System.out.println("      remap fundamental region pie slice");

            int nOldVerts = mesh.verts.size();
            System.out.println("          nOldVerts = "+nOldVerts);
            double oldVerts[][] = new double[nOldVerts][3];
            FORI (iOldVert, nOldVerts)
            {
                Mesh.Vertex vert = mesh.getVert(iOldVert);
                oldVerts[iOldVert][0] = vert.x();
                oldVerts[iOldVert][1] = vert.y();
                oldVerts[iOldVert][2] = vert.h(); // different from the other (hmm, should this be dependent on wrapAroundSphere instead? now I'm confused)
            }
            double oldBbox[][] = VecMath.bbox(oldVerts);
            double workAreaSize = (nOldVerts==0 ? 1. : MAX4(ABS(oldBbox[0][0]),
                                                            ABS(oldBbox[0][1]),
                                                            ABS(oldBbox[1][0]),
                                                            ABS(oldBbox[1][1])));

            // as recommended in FuzzyPointHashTable doc...
            double littleTol = 1e-12 * workAreaSize;
            double bigTol = 1e-10 * workAreaSize;
            double bucketSize = 1/1024. * workAreaSize;
            FuzzyPointHashTable newVertsTable = new FuzzyPointHashTable(littleTol,
                                                                        bigTol,
                                                                        bucketSize);
            Object dummy = new Object(); // we really want a hash set, not hash table, so need a dummy object, distinct from null

            FORI (iOldVert, nOldVerts)
            {
                double oldVert[] = oldVerts[iOldVert];
                double magnitude = MyMath.hypot(oldVert[0], oldVert[1]);
                double oldAngle = Math.atan2(oldVert[1], oldVert[0]);
                // find fraction in the canonical fundamental region...
                double frac = (oldAngle/(2*Math.PI) + .25) // so -90 degrees produces frac=0
                            * oldP;
                frac -= Math.floor(frac); // so frac should now be between 0 and 1

                if (false) // nah, this looks like hell
                {
                    // make it a conformal mapping (raising to a power in the complex plane)...
                    magnitude = Math.pow(magnitude, (double)oldP/(double)newP);
                }

                FORI (iNewImage, newP)
                {
                    double newAngle = (((iNewImage+frac)) / newP - .25) * (2*Math.PI);
                    double newVert[] = {
                        magnitude * Math.cos(newAngle),
                        magnitude * Math.sin(newAngle),
                    };
                    if (newVertsTable.put(newVert,dummy) == null) // i.e. if it wasn't already there
                    {
                        newVertsArrayList.add(new double[] {
                            newVert[0],
                            newVert[1],
                            oldVert[2], // takes one of the old heights arbitrarily, if multiple.  CBB: can we set it to average?
                        });
                    }
                }
            }
        } else if (oldP != 1 && oldQ != 1
                && newP != 1 && newQ != 1)
        {
            // Old and new fundamental regions are triangles.  Or something.
            System.out.println("      remap fundamental region quad");

            int nOldVerts = mesh.verts.size();
            System.out.println("          nOldVerts = "+nOldVerts);
            double oldVerts[][] = new double[nOldVerts][3];
            FORI (iOldVert, nOldVerts)
            {
                Mesh.Vertex vert = mesh.getVert(iOldVert);
                oldVerts[iOldVert][0] = vert.x();
                oldVerts[iOldVert][1] = vert.y();
                oldVerts[iOldVert][2] = vert.z(); // different from the other  (hmm, should this be dependent on wrapAroundSphere instead? now I'm confused)
            }
            double oldBbox[][] = VecMath.bbox(oldVerts);
            double workAreaSize = (nOldVerts==0 ? 1. : MAX4(ABS(oldBbox[0][0]),
                                                            ABS(oldBbox[0][1]),
                                                            ABS(oldBbox[1][0]),
                                                            ABS(oldBbox[1][1])));


            double oldGroup[][][] = SymmetryUtils.computeSymmetryGroup3d(
                oldP,
                oldQ,
                false, false, // no reflections taken into account here
                false); // repeat work-in-progress not taken into account here, yet

            System.out.println("          "+oldGroup.length+" old symmetries");

            double oldFundamentalRegionVerts[][] = SymmetryUtils.getFundamentalRegionVerts(oldP, oldQ, false);
            int gonality = oldFundamentalRegionVerts.length;
            assert_eq(gonality, 4); // because no reflections
            double oldFundamentalRegionInwardNormals[][] = new double[gonality][3];
            FORI (i, gonality)
            {
                VecMath.vxv3(oldFundamentalRegionInwardNormals[i],
                             oldFundamentalRegionVerts[i],
                             oldFundamentalRegionVerts[(i+1)%gonality]);
                VecMath.normalize(oldFundamentalRegionInwardNormals[i],
                                  oldFundamentalRegionInwardNormals[i]);
            }

            double oldImages[][] = new double[nOldVerts][3];
            {
                double oldImage[] = new double[3]; // scratch for loop
                double fakeBary[] = new double[gonality]; // scratch for loop

                FORI (iOldVert, nOldVerts)
                {
                    double oldVert[] = oldVerts[iOldVert];

                    // Which symmetry brings it into old fundamental region?
                    // It's fuzzy, so make it a contest.
                    double bestGoodness = Double.NEGATIVE_INFINITY;
                    FORI (iOldSymmetry, oldGroup.length)
                    {
                        // CBB: could premultiply the two matrices together, i.e. precompute all images of schwarz triangles. would be less work if lots of oldVerts.
                        VecMath.vxm(oldImage, oldVert, oldGroup[iOldSymmetry]);
                        VecMath.mxv(fakeBary, oldFundamentalRegionInwardNormals, oldImage);
                        double goodness = VecMath.min(fakeBary);
                        if (goodness > bestGoodness)
                        {
                            bestGoodness = goodness;
                            VecMath.copyvec(oldImages[iOldVert], oldImage);
                        }
                    }
                }
            }
            if (true)
            {
                // De-dup oldImages.
                // Note that there can actually still be dups, for images on the boundary of the fundamental region
                // when not reflective symmetry,
                // but comparatively few of them and we'll catch those later.
                // TODO: make a utility function out of deduping?
                int nDeDuped = 0;
                {
                    // TODO: make a FuzzyPointHashSet that does this?

                    Object dummy = new Object(); // we really want a hash set, not hash table, so need a dummy object, distinct from null
                    // as recommended in FuzzyPointHashTable doc...
                    double littleTol = 1e-12 * workAreaSize;
                    double bigTol = 1e-10 * workAreaSize;
                    double bucketSize = 1/1024. * workAreaSize;
                    FuzzyPointHashTable newVertsTable = new FuzzyPointHashTable(littleTol,
                                                                                bigTol,
                                                                                bucketSize);
                    FuzzyPointHashTable fuzzyPointHashTable = new FuzzyPointHashTable(littleTol, bigTol, bucketSize);
                    FORI (iOldVert, nOldVerts)
                        if (newVertsTable.put(oldImages[iOldVert],dummy) == null) // i.e. if it wasn't already there
                            VecMath.copyvec(oldImages[nDeDuped++], oldImages[iOldVert]);
                }
                System.out.println("          old images deduped "+oldImages.length+" -> "+nDeDuped);
                oldImages = (double[][])Arrays.subarray(oldImages, 0, nDeDuped);
            }

            double newImages[][] = new double[oldImages.length][3];

            double newFundamentalRegionVerts[][] = SymmetryUtils.getFundamentalRegionVerts(newP, newQ, false);
            assert_eq(newFundamentalRegionVerts.length, gonality);
            if (gonality == 3)
            {
                assert(false); // it turns out we only do this with rotational symmetry, so this doesn't happen
                double bary[] = new double[3]; // scratch for loop
                FORI (iImage, oldImages.length)
                {
                    double oldMagnitude = VecMath.normalize(oldImages[iImage],oldImages[iImage]); // destructive
                    VecMath.getSphericalAverageWeights(bary, oldFundamentalRegionVerts, oldImages[iImage]);
                    VecMath.sphericalAverage(newImages[iImage], newFundamentalRegionVerts, bary);
                    VecMath.vxs(newImages[iImage], newImages[iImage], oldMagnitude);
                }
            }
            else // gonality == 4
            {
                double oldTris[/*2*/][/*3*/][/*3*/] = {
                    {oldFundamentalRegionVerts[0],oldFundamentalRegionVerts[1],oldFundamentalRegionVerts[2]},
                    {oldFundamentalRegionVerts[0],oldFundamentalRegionVerts[2],oldFundamentalRegionVerts[3]},
                };
                double newTris[/*2*/][/*3*/][/*3*/] = {
                    {newFundamentalRegionVerts[0],newFundamentalRegionVerts[1],newFundamentalRegionVerts[2]},
                    {newFundamentalRegionVerts[0],newFundamentalRegionVerts[2],newFundamentalRegionVerts[3]},
                };
                double bary[] = new double[3]; // scratch for loop
                FORI (iImage, oldImages.length)
                {
                    int which = oldImages[iImage][0]>=0 ? 0 : 1;
                    double oldMagnitude = VecMath.normalize(oldImages[iImage],oldImages[iImage]); // destructive
                    VecMath.getSphericalAverageWeights(bary, oldTris[which], oldImages[iImage]);
                    VecMath.sphericalAverage(newImages[iImage], newTris[which], bary);
                    VecMath.vxs(newImages[iImage], newImages[iImage], oldMagnitude);
                }
            }

            double newGroup[][][] = SymmetryUtils.computeSymmetryGroup3d(
                newP,
                newQ,
                false, false, // no reflections taken into account here
                false); // repeat work-in-progress not taken into account here, yet
            System.out.println("          "+newGroup.length+" new symmetries");
            {
                Object dummy = new Object(); // we really want a hash set, not hash table, so need a dummy object, distinct from null
                // as recommended in FuzzyPointHashTable doc...
                double littleTol = 1e-12 * workAreaSize;
                double bigTol = 1e-10 * workAreaSize;
                double bucketSize = 1/1024. * workAreaSize;
                FuzzyPointHashTable newVertsTable = new FuzzyPointHashTable(littleTol,
                                                                            bigTol,
                                                                            bucketSize);
                double newVert[] = new double[3]; // scratch for loop
                // CBB: probably theres a more efficient algorithm; whatever
                FORI (iImage, newImages.length)
                {
                    FORI (iNewSymmetry, newGroup.length)
                    {
                        VecMath.vxm(newVert, newImages[iImage], newGroup[iNewSymmetry]);
                        if (newVertsTable.put(newVert,dummy) == null) // i.e. if it wasn't already there
                            newVertsArrayList.add(Arrays.append(newVert, 1.)); // xyzw (otherwise would be interpreted as xyh)
                    }
                }
                System.out.println("          new verts deduped "+(newImages.length*newGroup.length)+" -> "+newVertsArrayList.size());
            }

            if (false)
            {
                // HACK-- show the new fundamental region verts
                FORI (i, newFundamentalRegionVerts.length)
                    newVertsArrayList.add(Arrays.append(newFundamentalRegionVerts[i], 1.));
            }
            if (false)
            {
                // HACK-- show old images
                FORI (i, oldImages.length)
                    newVertsArrayList.add(Arrays.append(oldImages[i], 1.));
            }
            if (false)
            {
                // HACK-- show new images
                FORI (i, oldImages.length)
                    newVertsArrayList.add(Arrays.append(newImages[i], 1.));
            }
        }

        double newVerts[][] = new double[newVertsArrayList.size()][];
        newVertsArrayList.toArray(newVerts);
        newVertsArrayList = null;

        // For now, don't try to retain any connectivity.
        // A mesh will appear if "Keep delaunayized" is checked.
        Mesh answer = new Mesh(newVerts, new int[0][]);

        System.out.println("    out changeMeshRotationalSymmetry");
        return answer;
    } // changeMeshRotationalSymmetry

    public static final int FACING_UNKNOWN = 0;
    public static final int FACING_BACK = 1;
    public static final int FACING_SIDE = 2;
    public static final int FACING_FRONT = 3;
    public static void getFacings(double eyeInLocalSpace[],
                                  Mesh mesh, Mesh dualMesh, boolean meshIsReallyDualMesh,
                                  int faceFacings[],
                                  int edgeFacings[],
                                  int vertFacings[],
                                  boolean wrapAroundSphereFlagValue,
                                  boolean centerSphereFlagValue,
                                  double wrapSphereCurvatureValue)
    {
        int verboseLevel = 0;
        if (verboseLevel >= 1) System.out.println("    in getFacings");
        VecMath.fillvec(faceFacings, FACING_UNKNOWN);
        VecMath.fillvec(edgeFacings, FACING_UNKNOWN);
        VecMath.fillvec(vertFacings, FACING_UNKNOWN);

        // XXX wait, is there some confusion here? aren't some of the array sizes one more than this?
        int nVerts = mesh.verts.size();
        int nEdges = mesh.edges.size();
        int nDualVerts = dualMesh.verts.size();

        if (verboseLevel >= 1) System.out.println("      eyeInLocalSpace = "+VecMath.toString(eyeInLocalSpace));
        // compute face facings...
        if (verboseLevel >= 1) System.out.println("      computing face facings");


        // TODO: Do I need to abandon this first method??
        // Problem is, in wrapped-around-sphere case, if whole polyhedron is eyeward of the origin, it's impossible
        // to tell direction from 3d dual vertex position.
        // However, for paraboloid case, it's awesome!  It magically gives the right answer given dual vertex, although I don't understand why.
        if (false)
        {
            FORI (iFace, nDualVerts)
            {
                Mesh.Vertex dualVert = dualMesh.getVert(iFace);

                // plane is all points p such that p dot facePlaneNormal == facePlaneOffset

                double facePlaneNormal[];
                double facePlaneOffset;

                if (wrapAroundSphereFlagValue)
                {
                    // reciprocated wrt sphere.

                    // just work with frickin actual coords,
                    // homogeneous coords are too confusing
                    // and w=0 is exceedingly rare in wrapped-around-sphere case anyway.
                    // this is STILL too frickin complicated!

                    facePlaneNormal = new double[] {
                        dualVert.x(),
                        dualVert.y(),
                        centerSphereFlagValue ? dualVert.z() : dualVert.z() + 1./wrapSphereCurvatureValue
                    };
                    double dualVertDist2FromCenter = VecMath.normsqrd(facePlaneNormal);
                    double facePlaneSmallestPoint[] = VecMath.vxs(facePlaneNormal, 1./dualVertDist2FromCenter);
                    if (!centerSphereFlagValue)
                        facePlaneSmallestPoint[2] -= 1./wrapSphereCurvatureValue;
                    facePlaneOffset = VecMath.dot(facePlaneNormal, facePlaneSmallestPoint);

                    // Hmm, that's wrong if face plane is facing the origin...
                    // and useless if the face plane passes through the origin (in which case the dual vert is at infinity).
                    // How the heck can we tell??
                }
                else
                {
                    // reciprocated wrt paraboloid
                    facePlaneNormal = new double[] {dualVert.X(), dualVert.Y(), dualVert.W()}; // i.e. x,y,1.  not unit length.
                    facePlaneOffset = -dualVert.Z(); // i.e. z.  magic!  I don't know why, but this is the correct value
                }
                // XXX not sure the epsilons make sense... maybe normalize facePlaneNormal and offset, just so we can think straight about that?
                double frontness = VecMath.dot(facePlaneNormal, eyeInLocalSpace)
                          - facePlaneOffset;
                if (LT(frontness, 0., SQR(1e-6)))
                    faceFacings[iFace] = FACING_BACK;
                else if (GT(frontness, 0., SQR(1e-6)))
                    faceFacings[iFace] = FACING_FRONT;
                else
                    faceFacings[iFace] = FACING_SIDE;
            }
        }
        else
        {
            if (verboseLevel >= 1) System.out.println("          (NOT!)");
        }

        // Bleah, the faces that don't have dual verts
        // need to be computed by a separate method.
        // (and the above method sucks anyway, at least for wrapped-around-sphere).
        if (verboseLevel >= 1) System.out.println("      computing face for faces that don't have dual verts");
        FORI (iEdge, nEdges)
        {
            Mesh.Edge edgeI = mesh.getEdge(iEdge);
            Mesh.Edge dualEdgeI = dualMesh.getEdge(iEdge);
            Mesh.Vertex leftDualVert = dualEdgeI.finalVertex();
            int iLeftFace = leftDualVert==null ? nDualVerts : leftDualVert.myIndex();
            if (faceFacings[iLeftFace] == FACING_UNKNOWN)
            {
                if (verboseLevel >= 2) System.out.println("          iEdge = e"+iEdge+"/"+nEdges+" "+(edgeI.initialVertex()==null?"null":"v"+edgeI.initialVertex().myIndex())+"->"+(edgeI.finalVertex()==null?"null  ":"v"+edgeI.finalVertex().myIndex())+" ("+(edgeI.direction!=null?"has direction":"no direction")+")");
                double normal[] = {0,0,0}; // for starters
                double moment[] = {0,0,0}; // for starters
                double centroid[] = null;
                // XXX TODO: centroid of verts might be more robust than area centroid? yeah I think so, hmm
                double area = 0.;
                {
                    Mesh.Vertex v0 = edgeI.initialVertex();
                    if (v0 == null)
                    {
                        if (verboseLevel >= 2) System.out.println("              ouch! edge "+iEdge+" has null initial vertex ("+(edgeI.direction!=null?"has direction":"no direction")+")");
                        // This one shouldn't be a disaster; this face will be solved by some other edge on it.
                        continue;
                    }
                    // CBB: compute in homogeneous space?  Hmm that would be ambitious.
                    assert_ne(v0, null);
                    double v0coords[] = {v0.x(), v0.y(), v0.z()};
                    double v1coords[] = new double[3]; // scratch for loop
                    double v2coords[] = new double[3]; // scratch for loop
                    double thisCentroid[] = new double[3]; // scratch for loop
                    double thisWeightedNormal[] = new double[3]; // scratch for loop
                    Mesh.Edge edgeJ;
                    for (edgeJ = edgeI.next(); edgeJ.next() != edgeI; edgeJ = edgeJ.next())
                    {
                        Mesh.Vertex v1 = edgeJ.initialVertex();
                        Mesh.Vertex v2 = edgeJ.finalVertex();
                        // a bit hackish, but prevents weird computation using vertices we shouldn't be using
                        if (v1 != null && v1.weight < 0.) v1 = null;
                        if (v2 != null && v2.weight < 0.) v2 = null;
                        if (v1 == null && v2 == null)
                        {
                            // Happens when not "calc underside when delaunayizing"
                            // Not quite sure yet how to prevent these things from being drawn.  (e.g. the second sheet, when convex noise 1 starts from a square and I don't re-delaunayize with "calc underside when delaunayizing"=false at end)
                            if (verboseLevel >= 0) System.out.println("                  ouch! edge "+edgeJ.myIndex()+" has null initial and final vertex ("+(edgeJ.direction!=null?"has direction":"no direction")+")");
                            break;
                        }
                        else if (v1 == null)
                        {
                            if (verboseLevel >= 2) System.out.println("                  ouch! edge "+edgeJ.myIndex()+" has null initial vertex ("+(edgeJ.direction!=null?"has direction":"no direction")+")");
                            assert_ne(edgeJ.direction, null);
                            v2coords[0] = v2.x();
                            v2coords[1] = v2.y();
                            v2coords[2] = v2.z();
                            VecMath.vmv(3, v1coords, v2coords, edgeJ.direction);
                        }
                        else if (v2 == null)
                        {
                            if (verboseLevel >= 2) System.out.println("                  ouch! edge "+edgeJ.myIndex()+" has null final vertex ("+(edgeJ.direction!=null?"has direction":"no direction")+")");
                            assert_ne(edgeJ.direction, null);
                            v1coords[0] = v1.x();
                            v1coords[1] = v1.y();
                            v1coords[2] = v1.z();
                            VecMath.vpv(3, v2coords, v1coords, edgeJ.direction);
                        }
                        else
                        {
                            v1coords[0] = v1.x();
                            v1coords[1] = v1.y();
                            v1coords[2] = v1.z();
                            v2coords[0] = v2.x();
                            v2coords[1] = v2.y();
                            v2coords[2] = v2.z();
                        }
                        VecMath.vmv(v1coords, v1coords, v0coords); // so now relative to v0
                        VecMath.vmv(v2coords, v2coords, v0coords); // so now relative to v0
                        VecMath.vxv3(thisWeightedNormal, v1coords, v2coords);
                        VecMath.vpv(normal, normal, thisWeightedNormal);
                        if (verboseLevel >= 2) System.out.println("                  jEdge = e"+edgeJ.myIndex()+"/"+nEdges+" "+(edgeJ.initialVertex()==null?"null":"v"+edgeJ.initialVertex().myIndex())+"->"+(edgeJ.finalVertex()==null?"null  ":"v"+edgeJ.finalVertex().myIndex())+" adding weighted normal "+VecMath.toString(thisWeightedNormal));
                        double thisArea = VecMath.norm(thisWeightedNormal);
                        area += thisArea;
                        VecMath.sxvpsxv(thisCentroid, 1/3., v1coords, 1/3., v2coords); // relative to v0
                        VecMath.vpsxv(moment, moment, thisArea, thisCentroid);
                    }
                    if (edgeJ != edgeI) // if broke
                    {
                        if (verboseLevel >= 2) System.out.println("              ouch! continuing");
                    }
                    centroid = VecMath.vpsxv(v0coords, 1./area, moment);
                }
                if (verboseLevel >= 2) System.out.println("              normal = "+VecMath.toString(normal));
                if (verboseLevel >= 2) System.out.println("              eyeInLocalSpace-centroid = "+VecMath.toString(VecMath.vmv(eyeInLocalSpace, centroid)));
                double frontness = VecMath.dot(normal, eyeInLocalSpace)
                                 - VecMath.dot(normal, centroid);
                if (meshIsReallyDualMesh)
                    frontness *= -1;
                if (verboseLevel >= 2) System.out.println("              frontness = "+frontness);
                // XXX not sure the epsilons make sense... maybe normalize normal, just so we can think straight about that?
                if (LT(frontness, 0., SQR(1e-6)))
                    faceFacings[iLeftFace] = FACING_BACK;
                else if (GT(frontness, 0., SQR(1e-6)))
                    faceFacings[iLeftFace] = FACING_FRONT;
                else
                    faceFacings[iLeftFace] = FACING_SIDE;
                //PRINTVEC(normal);
            }
        }

        // TODO: explain exactly what UNKNOWN in faceFacings means
        if (verboseLevel >= 2)
        {
            FORI (i, faceFacings.length)
                if (faceFacings[i] == FACING_UNKNOWN)
                    OUT("HEY! faceFacings["+i+"/"+faceFacings.length+"] is UNKNOWN!");
        }

        // compute edge facings from incident face facings...
        if (verboseLevel >= 1) System.out.println("      computing edge facings");
        FORI (iEdge, nEdges)
        {
            if (edgeFacings[iEdge] == FACING_UNKNOWN)
            {
                Mesh.Edge edgeI = mesh.getEdge(iEdge);
                Mesh.Edge dualEdgeI = dualMesh.getEdge(iEdge);
                Mesh.Vertex leftDualVert = dualEdgeI.finalVertex();
                Mesh.Vertex rightDualVert = dualEdgeI.initialVertex();
                int iLeftFace = leftDualVert==null ? nDualVerts : leftDualVert.myIndex();
                int iRightFace = rightDualVert==null ? nDualVerts : rightDualVert.myIndex();
                int leftFaceFacing = faceFacings[iLeftFace];
                int rightFaceFacing = faceFacings[iRightFace];
                // UNKNOWN trumps all others
                edgeFacings[iEdge] = (leftFaceFacing==FACING_UNKNOWN || rightFaceFacing==FACING_UNKNOWN) ? FACING_UNKNOWN
                                   : leftFaceFacing==rightFaceFacing ? leftFaceFacing
                                   : FACING_SIDE;
                int oEdge = edgeI.opposite().myIndex();
                assert_eq(oEdge, (iEdge^1));
                edgeFacings[oEdge] = edgeFacings[iEdge];
            }
        }

        // TODO: explain exactly what UNKNOWN in edgeFacings means
        if (verboseLevel >= 2)
        {
            FORI (i, edgeFacings.length)
                if (edgeFacings[i] == FACING_UNKNOWN)
                    OUT("HEY! edgeFacings["+i+"/"+edgeFacings.length+"] is UNKNOWN!");
        }

        // compute vert facings from incident edge facings...
        if (verboseLevel >= 1) System.out.println("      computing vert facings");
        // bleah, need some other value for "not yet initialized"
        assert_ne(-1, FACING_UNKNOWN);
        VecMath.fillvec(vertFacings, -1);
        FORI (iEdge, nEdges)
        {
            // only need to do initial vertex-- edge.opposite() will do final vertex
            Mesh.Vertex v0 = mesh.getEdge(iEdge).initialVertex();
            if (v0 == null)
                continue;
            int i0 = v0.myIndex();
            if (vertFacings[i0] == -1) // uninitialized
                vertFacings[i0] = edgeFacings[iEdge];
            else if (vertFacings[i0] == FACING_UNKNOWN || edgeFacings[iEdge] == FACING_UNKNOWN)
                vertFacings[i0] = FACING_UNKNOWN;
            else if (vertFacings[i0] != edgeFacings[iEdge])
                vertFacings[i0] = FACING_SIDE;
            // otherwise leave it what it is
        }
        FORI (iVert, vertFacings.length)
        {
            if (vertFacings[iVert] == -1)
                vertFacings[iVert] = FACING_UNKNOWN;
        }

        // UNKNOWN in vertFacings means either it's an isolated vert,
        // or it's incident on an edge with UNKNOWN facing.

        if (verboseLevel >= 1)
        {
            OUT("      --------");
            final char facingToChar[] = {'?','-','0','+'};
            {
                StringBuffer sb = new StringBuffer();
                FORI (i, faceFacings.length)
                    sb.append(facingToChar[faceFacings[i]]);
                System.out.println("      face facings: "+sb);
            }
            {
                StringBuffer sb = new StringBuffer();
                FORI (i, edgeFacings.length)
                    sb.append(facingToChar[edgeFacings[i]]);
                System.out.println("      edge facings: "+sb);
            }
            {
                StringBuffer sb = new StringBuffer();
                FORI (i, vertFacings.length)
                    sb.append(facingToChar[vertFacings[i]]);
                System.out.println("      vert facings: "+sb);
            }
            OUT("      --------");
        }
        if (verboseLevel >= 1) System.out.println("    out getFacings");
    } // getFacings

    // CBB: probably doesn't work unless faces are convex
    // CBB: point can fall through cracks
    public static Mesh.Edge findSomeEdgeOnFaceVertIsIn(Mesh mesh, double x, double y)
    {

        boolean kissed = false;
        double twiceMostNegativeFaceArea = Double.POSITIVE_INFINITY;
        Mesh.Edge edgeOnMostNegativeFace = null;
        // XXX traverses each face of size n n times!  need to keep track of what we've done already
        int nEdges = mesh.edges.size();
        FORI (iEdge, nEdges)
        {
            boolean thisFaceIsGoodSoFar = true;
            Mesh.Edge edgeI = mesh.getEdge(iEdge);
            double twiceThisFaceArea = 0.;
            for (Mesh.Edge edge = edgeI;;)
            {
                double twiceThisTriArea = GeomUtils.twiceTriangleArea(
                    x, y,
                    edge.initialVertex().x(),
                    edge.initialVertex().y(),
                    edge.finalVertex().x(),
                    edge.finalVertex().y());
                if (twiceThisTriArea < 0)
                {
                    thisFaceIsGoodSoFar = false;
                    break; // out of this face
                }

                if ((edge = edge.next()) == edgeI)
                    break;
            }
            if (thisFaceIsGoodSoFar)
                return edgeI;
        }
        return null;
    } // findSomeEdgeOnFaceVertIsIn

    public static Mesh.Edge findSomeEdgeOnMostNegativeFace(Mesh mesh)
    {
        double twiceMostNegativeFaceArea = Double.POSITIVE_INFINITY;
        Mesh.Edge answer = null;
        int nEdges = mesh.edges.size();
        FORI (iEdge, nEdges)
        {
            Mesh.Edge edgeI = mesh.getEdge(iEdge);
            double x0 = edgeI.initialVertex().x();
            double y0 = edgeI.initialVertex().y();
            double twiceThisFaceArea = 0.;
            for (Mesh.Edge edge = edgeI;;)
            {
                double twiceThisTriArea = GeomUtils.twiceTriangleArea(
                    x0, y0,
                    edge.initialVertex().x(),
                    edge.initialVertex().y(),
                    edge.finalVertex().x(),
                    edge.finalVertex().y());
                twiceThisFaceArea += twiceThisTriArea;

                if ((edge = edge.next()) == edgeI)
                    break;
            }
            if (twiceThisFaceArea < twiceMostNegativeFaceArea)
            {
                twiceMostNegativeFaceArea = twiceThisFaceArea;
                answer = edgeI;
            }
        }
        return answer;
    } // findSomeEdgeOnMostNegativeFace

    public static double[][/*3*/] parseRadialHeightFieldPairs(String text)
    {
        String tokens[] = com.donhatchsw.compat.regex.split(text.trim(), "\\s+");
        if (tokens.length == 1 && tokens[0].equals("")) tokens = new String[]{}; // fix tokenization
        //PRINTARRAY(tokens);
        if (tokens.length % 2 != 0) return null;
        double pairs[][] = new double[tokens.length/2][2];
        FORI (i, tokens.length)
        {
            try
            {
                pairs[i/2][i%2] = Double.parseDouble(tokens[i]);
            }
            catch (NumberFormatException err)
            {
                return null;
            }
        }
        for (int i = 1; i < pairs.length; ++i)
        {
            if (!(pairs[i][0] >= (i==0?0.:pairs[i-1][0]))) return null; // radii must be nonnegative and nondecreasing
            if (!(pairs[i][1] >= (i==0?0.:pairs[i-1][1]))) return null; // dual radii must be nonnegative and nondecreasing
        }
        return pairs;
    } // parseRadialHeightFieldPairs

    // Sample:
    //   .06 .095 .14 .105    .16 .195 .24 .205    .26 .295  .34 .305  .36 .395  .44 .405  .46 .495
    //
    // Did this:
    //   Just noise 1000
    //   delaunayized on
    //   prewarp
    //   apply radial match (with above)
    //   delaunayized off
    //   "maybe make more difficult by truncating"
    //   start with upward Net
    //   make good
    // Haha, thought I found a counterexample for a few minutes!  But I think I applied radial match with delaunayized off :-(
    //
    public static void preWarpMeshForRadialHeightField(Mesh mesh, double pairs[][/*2*/])
    {
        if (pairs.length > 0) // prevent index out of bounds
        {
            FORIDOWN (iVert, mesh.verts.size())
            {
                Mesh.Vertex vert = mesh.getVert(iVert);
                // Treat initial x,y as target x,y in dual
                double xInDual = vert.x();
                double yInDual = vert.y();
                double rInDual = MyMath.hypot(xInDual, yInDual);

                // Find rInPrimal by mapping backwards.
                // Find interval [r0,r1) containing rInDual...
                // i is index of the upper end.
                int i = 0;
                while (i < pairs.length && rInDual >= pairs[i][1])
                    i++;
                double r0InDual = (i==0 ? 0. : pairs[i-1][1]);
                double r1InDual = (i==pairs.length ? pairs[i-1][1]+1+rInDual : pairs[i][1]);
                assert_le_lt(r0InDual, rInDual, r1InDual);
                double frac = (rInDual-r0InDual) / (r1InDual-r0InDual);
                assert_le_lt(0, frac, 1);
                double r0InPrimal = (i==0 ? 0. : pairs[i-1][0]);
                double r1InPrimal = (i==pairs.length ? pairs[i-1][0]+1+rInDual : pairs[i][0]);
                double rInPrimal = LERP(r0InPrimal, r1InPrimal, frac);
                double scale = rInPrimal==0. ? 42. : rInPrimal / rInDual; // avoid zero divide
                double xInPrimal = xInDual * scale;
                double yInPrimal = yInDual * scale;
                if (false)
                {
                    OUT("===============");
                    PRINT(xInDual);
                    PRINT(yInDual);
                    PRINT(rInDual);
                    PRINT(r0InDual);
                    PRINT(r1InDual);
                    PRINT(frac);
                    PRINT(r0InPrimal);
                    PRINT(r1InPrimal);
                    PRINT(xInPrimal);
                    PRINT(yInPrimal);
                    OUT("===============");
                }
                vert.setxyh(xInPrimal, yInPrimal, vert.h());
            }
        }
    } // preWarpMeshForRadialHeightField
    public static void unPreWarpMeshForRadialHeightField(Mesh mesh, double pairs[][/*2*/])
    {
        double reversedPairs[][] = new double[pairs.length][2];
        FORI (i, pairs.length)
        {
            reversedPairs[i][0] = pairs[i][1];
            reversedPairs[i][1] = pairs[i][0];
        }
        preWarpMeshForRadialHeightField(mesh, reversedPairs);
    } // unPreWarpMeshForRadialHeightField


    // TODO: move to MeshUtils probably
    // Apply a radial height field.
    // The spec is an array of pairs {primalRadius, dualRadius},
    // (where each dualRadius manifests as a slope in the primal).

    // Hmm, trying to solve the following from outward net only makes it worse:
    // (this was when I expressed the radial height field as triples)
    //      blue noise 4000, delaunayized
    //      0 0 .1  .1 0 10  .2 0 .1 .3 0 10  .4 0 .1  .5 0 10
    //
    //      just noise 1000, delaunayized
    //      0 0 .1  .2 .25 .1  .4 1 .1 
    // however, starting from upwards net usually solves it.  hmm.
    public static void applyRadialHeightFieldPairsToMesh(Mesh mesh, double pairs[][])
    {
        int verboseLevel = 2; // 1: in/out, 2: nice description, 3: gory
        if (verboseLevel >= 1) OUT("    in applyRadialHeightFieldPairsToMesh(pairs="+Arrays.toStringCompact(pairs)+")");
        // Assumes all values are nonnegative and nondecreasing, since generated by parseRadialHeightFieldPairs

        double radii[] = new double[pairs.length + 1];
        double positions[] = new double[pairs.length + 1];
        double velocities[] = new double[pairs.length + 1];
        double accelerations[] = new double[pairs.length + 1];
        {
            double r = 0.; // accumulated radius in primal
            double p = 0.; // accumulated position (height)
            double v = 0.; // accumulated velocity (radius in dual)
            double a = 0.; // accumulated acceleration
        }
        if (true)
        {
            radii[0] = 0.;
            positions[0] = 0.;
            velocities[0] = 0.;
            FORI (i, pairs.length)
            {
                radii[i+1] = pairs[i][0];
                velocities[i+1] = pairs[i][1];
                double dt = radii[i+1] - radii[i];
                double dv = velocities[i+1] - velocities[i];
                accelerations[i] = dv / dt; // ok if infinite, that means this interval won't be used for calculations
                if (false)
                {
                    // Correct but blows up if acceleration is infinite
                    positions[i+1] = positions[i] + velocities[i]*dt + .5*accelerations[i]*(dt*dt);
                }
                else
                {
                    // Note that accelerations[i]*(dt*dt) == dv*dt,
                    // which avoids zero-divide.
                    positions[i+1] = positions[i] + velocities[i]*dt + .5*dv*dt;
                }
            }
            accelerations[pairs.length] = 1.; // so primal matches dual out to infinity
        }

        if (true)
        {
            if (verboseLevel >= 2) OUT("      Description:");
            FORI (i, pairs.length+1)
            {
                if (verboseLevel >= 2) OUT("          r = "+radii[i]+" (radius in primal)");
                if (verboseLevel >= 2) OUT("              p = "+positions[i]);
                if (verboseLevel >= 2) OUT("              v = "+velocities[i]+" (radius in dual)");
                if (verboseLevel >= 2) OUT("              a = "+accelerations[i]);
            }
        }
        if (verboseLevel >= 2) PRINTVEC(radii);
        if (verboseLevel >= 2) PRINTVEC(positions);
        if (verboseLevel >= 2) PRINTVEC(velocities);
        if (verboseLevel >= 2) PRINTVEC(accelerations);

        FORIDOWN (iVert, mesh.verts.size())
        {
            Mesh.Vertex vert = mesh.getVert(iVert);
            double x = vert.x();
            double y = vert.y();
            double r = MyMath.hypot(x, y);
            if (verboseLevel >= 3) OUT("==========");
            if (verboseLevel >= 3) PRINT(iVert);
            if (verboseLevel >= 3) PRINT(x);
            if (verboseLevel >= 3) PRINT(y);
            if (verboseLevel >= 3) PRINT(r);

            int i = 0;
            // could do binary search but whatever.
            // find the interval [r0,r1) that contains r.
            while (i+1 < radii.length && r >= radii[i+1])
                i++;
            if (verboseLevel >= 3) PRINT(i);

            double t = r - radii[i];
            if (verboseLevel >= 3) PRINT(t);
            assert_ne(1./accelerations[i], 0.); // not infinite
            assert_eq(accelerations[i], accelerations[i]); // not NaN
            double h = positions[i] + velocities[i]*t + .5*accelerations[i]*(t*t);
            if (verboseLevel >= 3) PRINT(h);

            // we were doing positive, but really should be concave with mouth downwards
            h *= -1;
            if (verboseLevel >= 3) PRINT(h);
            // change to offset from canonical paraboloid
            h -= -.5*r*r;
            if (verboseLevel >= 3) PRINT(h);
            if (verboseLevel >= 3) OUT("==========");

            vert.setxyh(x, y, h);
        }
        if (verboseLevel >= 1) OUT("    out applyRadialHeightFieldPairsToMesh(pairs="+Arrays.toStringCompact(pairs)+")");
    } // applyRadialHeightFieldPairsToMesh

    public static Mesh.Edge[] getVertToFirstEdgeOut(Mesh mesh)
    {
        int nVerts = mesh.verts.size();
        int nEdges = mesh.edges.size();
        Mesh.Edge answer[] = new Mesh.Edge[nVerts]; // all null initially
        FORI (iEdge, nEdges)
        {
            Mesh.Edge edge = mesh.getEdge(iEdge);
            Mesh.Vertex initialVertex = edge.initialVertex();
            if (initialVertex != null)
            {
                int iVert = initialVertex.myIndex();
                if (answer[iVert] == null)
                    answer[iVert] = edge;
            }
        }
        return answer;
    } // getVertToFirstEdgeOut

    // Greedily find a maximal list of verts such that no vert in the list has any neighbor in the list.
    public static int[] findMaximalIndependentVertexSet(Mesh mesh, java.util.Random rng)
    {
        int verboseLevel = 0;
        int nVerts = mesh.verts.size();
        int nEdges = mesh.edges.size();

        int answer[] = new int[nVerts]; // will shrink at end
        int answerSize = 0;

        Mesh.Edge vertToAnyEdgeOut[] = getVertToFirstEdgeOut(mesh);

        int vertIndexToCandidateIndex[] = VecMath.identityperm(nVerts);
        int candidates[] = VecMath.identityperm(nVerts);
        int nCandidates = nVerts;

        // Make verts incident on infinite edges ineligible
        FORI (iEdge, nEdges)
        {
            Mesh.Edge edge = mesh.getEdge(iEdge);
            if (edge.initialVertex() != null && edge.finalVertex() == null)
            {
                int iVert = edge.initialVertex().myIndex();
                int iCandidate = vertIndexToCandidateIndex[iVert];
                if (iCandidate != -1)
                {
                    assert_eq(candidates[iCandidate], iVert);
                    // dup code alert: same as below
                    vertIndexToCandidateIndex[candidates[nCandidates-1]] = iCandidate;
                    vertIndexToCandidateIndex[iVert] = -1;
                    candidates[iCandidate] = candidates[nCandidates-1];
                    candidates[nCandidates-1] = -1;
                    --nCandidates;
                }
            }
        }

        while (nCandidates > 0)
        {
            if (verboseLevel >= 2) OUT("      top of loop");
            if (verboseLevel >= 2) OUT("              answer = "+Arrays.toStringCompact(Arrays.subarray(answer, 0, answerSize)));
            if (verboseLevel >= 2) OUT("              candidates = "+Arrays.toStringCompact(Arrays.subarray(candidates, 0, nCandidates)));
            if (verboseLevel >= 2) OUT("              vertIndexToCandidateIndex = "+Arrays.toStringCompact(vertIndexToCandidateIndex));
            int iCandidate = rng.nextInt(nCandidates);
            if (verboseLevel >= 2) OUT("          iCandidate = "+iCandidate);
            int iVert = candidates[iCandidate];
            if (verboseLevel >= 2) OUT("          iVert = "+iVert);
            assert_eq(vertIndexToCandidateIndex[iVert], iCandidate);

            // Add it to the set
            answer[answerSize++] = iVert;

            // Remove it and all its neighbors from candidates list

            // dup code alert: same as below
            vertIndexToCandidateIndex[candidates[nCandidates-1]] = iCandidate;
            vertIndexToCandidateIndex[iVert] = -1;
            candidates[iCandidate] = candidates[nCandidates-1];
            candidates[nCandidates-1] = -1;
            --nCandidates;

            if (verboseLevel >= 2) OUT("          after transferring to answer:");
            if (verboseLevel >= 2) OUT("              answer = "+Arrays.toStringCompact(Arrays.subarray(answer, 0, answerSize)));
            if (verboseLevel >= 2) OUT("              candidates = "+Arrays.toStringCompact(Arrays.subarray(candidates, 0, nCandidates)));
            if (verboseLevel >= 2) OUT("              vertIndexToCandidateIndex = "+Arrays.toStringCompact(vertIndexToCandidateIndex));

            if (false)
            {
                // sanity check
                FORI (i, nCandidates)
                    assert_eq(vertIndexToCandidateIndex[candidates[i]], i);
                FORI (i, nVerts)
                    if (vertIndexToCandidateIndex[i] != -1)
                    {
                        assert_lt(vertIndexToCandidateIndex[i], nCandidates);
                        assert_eq(candidates[vertIndexToCandidateIndex[i]], i);
                    }
                for (int i = nCandidates; i < candidates.length; ++i)
                    assert_eq(candidates[i], -1);
            }

            Mesh.Edge edge0 = vertToAnyEdgeOut[iVert];
            assert_ne(edge0, null);
            Mesh.Edge edge = edge0;
            do {
                Mesh.Vertex finalVertex = edge.finalVertex();
                if (finalVertex != null)
                {
                    iVert = finalVertex.myIndex();
                    iCandidate = vertIndexToCandidateIndex[iVert];
                    if (iCandidate != -1)
                    {
                        if (verboseLevel >= 2) OUT("              neighbor v"+iVert+" is now ineligible");
                        assert_eq(candidates[iCandidate], iVert);

                        // dup code alert: same as above
                        vertIndexToCandidateIndex[candidates[nCandidates-1]] = iCandidate;
                        vertIndexToCandidateIndex[iVert] = -1;
                        candidates[iCandidate] = candidates[nCandidates-1];
                        candidates[nCandidates-1] = -1;
                        --nCandidates;
                    }
                    else
                    {
                        if (verboseLevel >= 2) OUT("              (neighbor v"+iVert+" already ineligible)");
                    }
                }
            } while ((edge = edge.opposite().next()) != edge0);
        }
        answer = (int[])Arrays.subarray(answer, 0, answerSize);
        return answer;
    } // findMaximalIndependentVertexSet

    // Observation: sometimes truncating a dual vertex
    // makes unfolding more difficult, in the sense that
    // something that was previously an unfolding is no longer.
    // See if we can exploit this.
    public static void maybeMakeMoreDifficultByTruncatingDual(Mesh mesh,
                                                              Mesh dualMesh,
                                                              double truncationFrac,
                                                              java.util.Random rng)
    {
        OUT("    in maybeMakeMoreDifficultByTruncatingDual");
        int nEdges = mesh.edges.size();
        assert_eq(nEdges, dualMesh.edges.size());
        int nDualVerts = dualMesh.verts.size();

        // First find a maximal independent set of dual vertices (i.e. no pair of neighbors), greedily...
        int maximalIndependentDualVertSet[] = findMaximalIndependentVertexSet(dualMesh, rng);
        OUT("      maximalIndependentDualVertSet = "+Arrays.toStringCompact(maximalIndependentDualVertSet));
        OUT("      maximalIndependentDualVertSet.length = "+maximalIndependentDualVertSet.length);
        Mesh.Edge dualVertToFirstDualEdgeOut[] = getVertToFirstEdgeOut(dualMesh);

        double scratch[] = new double[3];
        FORI (i, maximalIndependentDualVertSet.length)
        {
            int iDualVert = maximalIndependentDualVertSet[i];
            Mesh.Edge dualEdge0 = dualVertToFirstDualEdgeOut[iDualVert];
            // dual mesh is trivalent, so...
            assert(dualEdge0.opposite().next()
                            .opposite().next()
                            .opposite().next() == dualEdge0);
            Mesh.Vertex v0 = dualMesh.getVert(iDualVert);
            Mesh.Vertex v1 = dualEdge0.finalVertex();
            Mesh.Vertex v2 = dualEdge0.opposite().next().finalVertex();
            Mesh.Vertex v3 = dualEdge0.opposite().next().opposite().next().finalVertex();

            double x0 = v0.x(), y0 = v0.y(), h0 = v0.h();
            double x1 = v1.x(), y1 = v1.y(), h1 = v1.h();
            double x2 = v2.x(), y2 = v2.y(), h2 = v2.h();
            double x3 = v3.x(), y3 = v3.y(), h3 = v3.h();

            // convert from height-above-paraboloid to euclidean ("actual")
            h0 -= .5 * (SQR(x0) + SQR(y0));
            h1 -= .5 * (SQR(x1) + SQR(y1));
            h2 -= .5 * (SQR(x2) + SQR(y2));
            h3 -= .5 * (SQR(x3) + SQR(y3));

            // lerp in euclidean space
            x1 = LERP(x0, x1, truncationFrac); y1 = LERP(y0, y1, truncationFrac); h1 = LERP(h0, h1, truncationFrac);
            x2 = LERP(x0, x2, truncationFrac); y2 = LERP(y0, y2, truncationFrac); h2 = LERP(h0, h2, truncationFrac);
            x3 = LERP(x0, x3, truncationFrac); y3 = LERP(y0, y3, truncationFrac); h3 = LERP(h0, h3, truncationFrac);

            // convert from euclidean back to height-above-paraboloid
            h0 += .5 * (SQR(x0) + SQR(y0));
            h1 += .5 * (SQR(x1) + SQR(y1));
            h2 += .5 * (SQR(x2) + SQR(y2));
            h3 += .5 * (SQR(x3) + SQR(y3));

            GeomUtils.SolveForDualPoint(x1, y1, h1,
                                        x2, y2, h2,
                                        x3, y3, h3,
                                        scratch,
                                        false,false,0.);
            double x = scratch[0];
            double y = scratch[1];
            double h = scratch[2];

            mesh.addIsolatedVertex(x, y, h);
            mesh.kisIsolatedVertex(mesh.getVert(mesh.verts.size()-1),
                                   mesh.getEdge(dualEdge0.opposite().myIndex())); // I had 50% chance of getting this right
        }
        OUT("    out maybeMakeMoreDifficultByTruncatingDual");
    } // maybeMakeMoreDifficultByTruncating

}  // class MeshUtils
