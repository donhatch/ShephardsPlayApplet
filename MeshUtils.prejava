#include "macros.h"

import com.donhatchsw.compat.ArrayList;
import com.donhatchsw.util.Arrays;
import com.donhatchsw.util.FuzzyPointHashTable;
import com.donhatchsw.util.MergeFind;
import com.donhatchsw.util.MyMath;
import com.donhatchsw.util.SortStuff;
import com.donhatchsw.util.VecMath;

final public class MeshUtils
{
    private MeshUtils(){ throw new AssertionError(); } // non-instantiatable util class

    public static double[][/*3*/] getMeshVertsXYH(Mesh mesh)
    {
        int nVerts = mesh.verts.size();
        double answer[][] = new double[nVerts][3];

        FORI (iVert, nVerts)
        {
            Mesh.Vertex v = mesh.getVert(iVert);
            answer[iVert][0] = v.x();
            answer[iVert][1] = v.y();
            answer[iVert][2] = v.h();
        }
        return answer;
    }

    // If canonicalOrder flag, order each face so that least-index vertex is first,
    // and then sort faces by increasing size and then increasing contents.
    // and then sort faces by increasing size and then contents.
    public static int[][] getMeshFaces(Mesh mesh, boolean canonicalOrderFlag)
    {
        boolean seenEdge[] = new boolean[mesh.edges.size()]; // all false initially
        int[][] faces = new int[mesh.edges.size()][];
        int[] scratchFace = new int[mesh.edges.size()]; // probably safer than mesh.verts.size()
        int nFaces = 0;
        FORIDOWN(iEdge, mesh.edges.size())
        {
            if (seenEdge[iEdge]) continue;
            Mesh.Edge edge0 = mesh.getEdge(iEdge);
            int faceSize = 0;
            Mesh.Edge edge = edge0;
            do {
                seenEdge[edge.myIndex()] = true;
                scratchFace[faceSize++] = edge.initialVertex().myIndex();
            } while ((edge = edge.next()) != edge0);
            faces[nFaces++] = (int[])Arrays.subarray(scratchFace, 0, faceSize);
        }
        faces = (int[][])Arrays.subarray(faces, 0, nFaces);

        if (canonicalOrderFlag)
        {
            FORIDOWN(iFace, faces.length)
            {
                int face[] = faces[iFace];
                int mini = VecMath.mini(face);
                System.arraycopy(face, mini,
                                 scratchFace, 0,
                                 face.length - mini);
                System.arraycopy(face, 0,
                                 scratchFace, face.length - mini,
                                 mini);
                System.arraycopy(scratchFace, 0,
                                 face, 0,
                                 face.length);
            }
            SortStuff.sort(faces, new SortStuff.Comparator() {
                public int compare(Object a, Object b)
                {
                    // TODO: call it aFace, bFace
                    int aFace[] = (int[])a;
                    int bFace[] = (int[])b;
                    if (aFace.length < bFace.length) return -1;
                    if (aFace.length > bFace.length) return 1;
                    for (int i = 0; i < aFace.length; ++i)
                    {
                        if (aFace[i] < bFace[i]) return -1;
                        if (aFace[i] > bFace[i]) return 1;
                    }
                    return 0;
                }
            });
        }
        return faces;
    } // getMeshFaces

    private static double detDestructiveDouble(int n, java.math.BigInteger M[/*n*/][/*n*/])
    {
        // Not really destructive.
        double Mdouble[][] = new double[n][n];
        for (int i = 0; i < n; ++i)
        for (int j = 0; j < n; ++j)
            Mdouble[i][j] = M[i][j].doubleValue();
        double answer = VecMath.detDestructive(Mdouble);
        return answer;
    }

    // Return an array of BigIntegers whose product is the determinant in question.
    // First entry will be 1 or -1, the others will be positive.
    private static java.math.BigInteger[] factorizeDetDestructive(int n, java.math.BigInteger M[][])
    {
        int verboseLevel = 0;
        java.math.BigInteger ZERO = java.math.BigInteger.ZERO;
        java.math.BigInteger ONE = java.math.BigInteger.ONE;
        if (verboseLevel >= 1) OUT("        in factorizeDetDestructive(n="+n+")");
        if (verboseLevel >= 1) OUT("          before:");
        if (verboseLevel >= 1) PRINTMAT(M);
        if (verboseLevel >= 1) PRINT(n);
        int sign = 1;
        FORI (i, n)
        {
            if (verboseLevel >= 2) OUT("              i="+i);
            if (verboseLevel >= 2) PRINTMAT(M);

            boolean pivotFlag = true;
            if (pivotFlag)
            {
                // Optional, but helps keep numbers relatively small:
                // Choose the pivot to be the smallest-magnitude entry in [>=i][>=i].
                // This is a heuristic; I actually don't know the best way
                // to do this.
                int jPivot = -1;
                int kPivot = -1;
                java.math.BigInteger absPivot = null;
                for (int j = i; j < n; ++j)
                for (int k = i; k < n; ++k)
                {
                    if (M[j][k].signum() != 0)
                    {
                        java.math.BigInteger absEntry = M[j][k].abs();
                        if (absPivot == null || absEntry.compareTo(absPivot) < 0)
                        {
                            jPivot = j;
                            kPivot = k;
                            absPivot = absEntry;
                        }
                    }
                }
                if (verboseLevel >= 2) OUT("              jPivot="+jPivot);
                if (verboseLevel >= 2) OUT("              kPivot="+kPivot);
                if (absPivot != null)
                {
                    if (jPivot != i)
                    {
                        java.math.BigInteger temp[];
                        SWAP(M[i], M[jPivot], temp);
                        sign *= -1;
                    }
                    if (kPivot != i)
                    {
                        // CBB: maybe maintain a column permutation instead of all these swaps?
                        java.math.BigInteger temp;
                        for (int j = i; j < n; ++j)
                            SWAP(M[j][i], M[j][kPivot], temp);
                        sign *= -1;
                    }
                }
                if (verboseLevel >= 2) OUT("                  after pivoting:");
                if (verboseLevel >= 2) PRINTMAT(M);
            }

            // Make sure everything we're going to deal with in this column is nonnegative
            for (int j = i; j < n; ++j)
            {
                if (M[j][i].signum() < 0)
                {
                    sign *= -1;
                    for (int k = i; k < n; ++k)
                        M[j][k] = M[j][k].negate();
                }
            }
            if (verboseLevel >= 2) OUT("                  after nonnegativizing:");
            if (verboseLevel >= 2) PRINTMAT(M);

            if (verboseLevel >= 2) OUT("                  after fixing:");
            if (verboseLevel >= 2) PRINTMAT(M);
            // Zero out all entries [>i][i]
            // by doing row operations against row i.
            for (int j = i+1; j < n; ++j)
            {
                if (verboseLevel >= 3) OUT("                  j="+j);
                assert(M[j][i].signum() >= 0);
                int iters = 0;
                int maxIters = 1000;
                // CBB: this isn't as efficient as it could be; should use CRT instead, I think.
                while (M[j][i].signum() != 0)
                {
                    iters++;
                    assert(iters < maxIters);
                    java.math.BigInteger a = M[i][i];
                    java.math.BigInteger b = M[j][i];
                    if (verboseLevel >= 3) OUT("                      a = "+a);
                    if (verboseLevel >= 3) OUT("                      b = "+b);
                    java.math.BigInteger q = a.divide(b);
                    // a,b = b,a%b
                    // One step in euclidean algorithm: a -= q * b, then swap a,b
                    // Do it to the whole row.
                    for (int k = i; k < n; ++k)
                    {
                        //M[i][k] -= q * M[j][k];
                        M[i][k] = M[i][k].subtract(M[j][k].multiply(q));
                    }
                    java.math.BigInteger temp[];
                    SWAP(M[i], M[j], temp);
                    sign *= -1;
                }
            }
        }
        if (verboseLevel >= 1) OUT("      after:");
        if (verboseLevel >= 1) PRINTMAT(M);
        java.math.BigInteger answer[] = new java.math.BigInteger[n+1];
        answer[0] = sign<0 ? ONE.negate()
                           : ONE;
        for (int i = 0; i < n; ++i)
            answer[i+1] = M[i][i];
        if (verboseLevel >= 1) OUT("    out factorizeDetDestructive(n="+n+"), returning "+VecMath.toString(answer));
        return answer;
    }
    // Unfortunately not sure whether I should be returning long or double.
    // Long might be more exact, but can overflow.
    private static java.math.BigInteger detDestructiveBigInteger(int n, java.math.BigInteger M[][])
    {
        int verboseLevel = 1;
        if (verboseLevel >= 1) OUT("    in detDestructiveLong(n="+n+")");
        java.math.BigInteger factors[] = factorizeDetDestructive(n, M);
        java.math.BigInteger answer = java.math.BigInteger.ONE;
        for (int i = 0; i < factors.length; ++i)
            answer = answer.multiply(factors[i]);
        if (verboseLevel >= 1) OUT("    out detDestructiveLong("+n+"), returning "+answer);
        return answer;
    }

    // Uses Kirchoff's theorem. https://en.wikipedia.org/wiki/Kirchhoff%27s_theorem
    public static java.math.BigInteger countSpanningTrees(Mesh mesh)
    {
        OUT("    in countSpanningTrees");
        java.math.BigInteger ZERO = java.math.BigInteger.ZERO;
        java.math.BigInteger ONE = java.math.BigInteger.ONE;
        int nVerts = mesh.verts.size();
        if (nVerts == 0)
            return ZERO;
        java.math.BigInteger laplacian[][] = new java.math.BigInteger[nVerts+1][nVerts+1];
        for (int i = 0; i < laplacian.length; ++i)
        for (int j = 0; j < laplacian[0].length; ++j)
            laplacian[i][j] = ZERO;

        int nEdges = mesh.edges.size();
        for (int iEdge = 0; iEdge < nEdges; ++iEdge)
        {
            Mesh.Edge edge = mesh.getEdge(iEdge);
            Mesh.Vertex v0 = edge.initialVertex();
            Mesh.Vertex v1 = edge.finalVertex();
            int i0 = v0==null ? nVerts : v0.myIndex();
            int i1 = v1==null ? nVerts : v1.myIndex();
            if (i0 != i1) // self-loops are irrelevant
            {
                laplacian[i0][i0] = laplacian[i0][i0].add(ONE);
                laplacian[i0][i1] = laplacian[i0][i1].subtract(ONE);
            }
        }
        PRINTMAT(laplacian);
        boolean hasEdgesToNowhere = laplacian[nVerts][nVerts].signum() != 0;
        PRINT(hasEdgesToNowhere);
        java.math.BigInteger detBigInteger = detDestructiveBigInteger(
                                  hasEdgesToNowhere ? nVerts : nVerts-1,
                                  (java.math.BigInteger[][])Arrays.copy(laplacian, 2));
        PRINT(detBigInteger);
        PRINT(detBigInteger.doubleValue());
        assert(detBigInteger.signum() >= 0);
        double detDouble = detDestructiveDouble(hasEdgesToNowhere ? nVerts : nVerts-1,
                                          laplacian); // all but last nontrivial row&column
        assert(detDouble >= 0);
        PRINT(detDouble);
        assert_almost_eq(detBigInteger.doubleValue(), detDouble, detDouble*1e-12);
        OUT("    out countSpanningTrees, returning "+detBigInteger);
        return detBigInteger;
    } // countSpanningTrees

    // Simpler mesh data structure, suitable for running
    // the algorithm from David Bruce Wilson
    // "Generating Random Spanning Trees More Quickly than the Cover Time".
    //
    // Subtleties:
    //     - Depending on how original mesh was constructed,
    //       it might have edges leading nowhere or coming from nowhere.
    //       The "nowhere" gets made into a vertex (the "infinite vertex").
    //     - We might or might not want to consider all inside-out vertices
    //       (i.e. those with weight < 0) to be part of the infinite vertex.
    //       This is a param to the constructor.
    public static class SimplerMeshDataStructure
    {
        public int e2v[/*nEdges*/][/*2*/]; // edge to verts
        public int v2e[/*nVerts*/][]; // vert to edges out

        public SimplerMeshDataStructure(Mesh mesh, boolean mergeInsideOutVertsIntoInfiniteVert)
        {
            int nVerts = mesh.verts.size(); // may add 1 though
            int nEdges = mesh.edges.size();
            this.e2v = new int[nEdges][2];

            int e2next[] = new int[nEdges];
            boolean infiniteVertUsed = false; // until proven otherwise
            FORI (iEdge, nEdges)
            {
                Mesh.Edge edge = mesh.getEdge(iEdge);
                assert(edge.myIndex() == iEdge);
                assert(edge.opposite().myIndex() == (iEdge^1));
                Mesh.Vertex v0 = edge.initialVertex();
                Mesh.Vertex v1 = edge.finalVertex();
                if (v0 == null || v1 == null)
                    infiniteVertUsed = true;
                int i0 = v0==null ? nVerts : v0.myIndex();
                int i1 = v1==null ? nVerts : v1.myIndex();
                e2v[iEdge][0] = i0;
                e2v[iEdge][1] = i1;
                Mesh.Edge next = edge.next();
                if (next == null)
                {
                    // final vertex is the infinite one; to find next, need to walk backwards around the face
                    next = edge;
                    while (next.prev() != null)
                        next = next.prev();
                }
                e2next[iEdge] = next.myIndex();
            }
            if (mergeInsideOutVertsIntoInfiniteVert)
            {
                boolean isInsideOut[] = new boolean[nVerts+1];
                FORI (iVert, nVerts)
                    isInsideOut[iVert] = (mesh.getVert(iVert).weight < 0);
                isInsideOut[nVerts] = true; // the infinite one, if any
                PRINTVEC(isInsideOut);
                FORI (iEdge, nEdges)
                    FORI (iVertThisEdge, 2)
                    {
                        if (isInsideOut[e2v[iEdge][iVertThisEdge]])
                        {
                            e2v[iEdge][iVertThisEdge] = nVerts;
                            infiniteVertUsed = true;
                        }
                    }
                // Note that it may be that some original verts are now unused in e2v
            }
            if (infiniteVertUsed)
                nVerts++;
            this.v2e = new int[nVerts][];
            {
                int arities[] = new int[nVerts]; // zeros initially
                FORI (iEdge, nEdges)
                    arities[e2v[iEdge][0]]++;
                FORI (iVert, nVerts)
                {
                    v2e[iVert] = new int[arities[iVert]];
                    arities[iVert] = 0;
                }
                FORI (iEdge, nEdges)
                {
                    int iVert = e2v[iEdge][0];
                    v2e[iVert][arities[iVert]++] = iEdge;
                }
                FORI (iVert, nVerts)
                {
                    assert_eq(v2e[iVert].length, arities[iVert]);
                    FORI (iEdgeOut, v2e[iVert].length)
                        assert_eq(e2v[v2e[iVert][iEdgeOut]][0], iVert);
                }
            }
        } // SimplerMeshDataStructure ctor

        public boolean isConnectedExceptMaybeForIsolatedVerts()
        {
            // DFS is actually faster supposedly but whatever
            int nVerts = v2e.length;
            int nEdges = e2v.length;
            MergeFind mergeFind = new MergeFind(nVerts);
            FORI (iEdge, nEdges)
            {
                int iVert = e2v[iEdge][0];
                int jVert = e2v[iEdge][1];
                mergeFind.merge(iVert, jVert);
            }
            int found = -1;
            FORI (iVert, nVerts)
            {
                if (v2e[iVert].length == 0) continue; // vertex got removed (or was isolated)
                if (found == -1)
                    found = mergeFind.find(iVert);
                else if (mergeFind.find(iVert) != found)
                    return false;
            }
            return true;
        } // isConnectedExceptMaybeForIsolatedVerts

        // Do not call this unless connected! (in the sense that isConnectedExceptMaybeForIsolatedVerts returns).
        public boolean[/*nEdges/2*/] randomSpanningTree(java.util.Random generator)
        {
            if (e2v.length == 0)
                return new boolean[0];
            // Use uniform random spanning tree algorithm, from David Bruce Wilson
            // "Generating Random Spanning Trees More Quickly than the Cover Time"
            // Must start with random vertex of random edge.
            int r = e2v[generator.nextInt(e2v.length)][generator.nextInt(2)];
            int nVerts = v2e.length;
            boolean inTree[] = new boolean[nVerts]; // false initially
            int theEdgeOut[] = new int[nVerts];
            theEdgeOut[r] = -1;
            inTree[r] = true;
            FORI (iVert, nVerts)
            {
                if (v2e[iVert].length == 0)
                    continue; // the vertex got removed (probably merged into the infinite vertex)
                for (int u = iVert; !inTree[u]; u = e2v[theEdgeOut[u]][1])
                    theEdgeOut[u] = v2e[u][generator.nextInt(v2e[u].length)];
                for (int u = iVert; !inTree[u]; u = e2v[theEdgeOut[u]][1])
                    inTree[u] = true;
            }
            boolean answer[] = new boolean[e2v.length/2]; // all false initially
            FORI (iVert, nVerts)
            {
                if (v2e[iVert].length == 0)
                    continue; // the vertex got removed (probably merged into the infinite vertex)
                int iEdge = theEdgeOut[iVert];
                assert((iEdge == -1) == (iVert==r));
                if (iEdge != -1)
                {
                    assert(e2v[iEdge][0] == iVert);
                    answer[iEdge/2] = true;
                }
            }
            return answer;
        } // randomSpanningTree

        public int[] getVertToParentEdgeOut(int root,
                                            boolean undirectedEdgeIsInSpanningTree[/*nUndirectedEdges*/])
        {
            int verboseLevel = 0;
            if (verboseLevel >= 1) System.out.println("in getVertToParentEdgeOut");
            // TODO: BUG: VecMath.toString messes up on int[][], it omits final closing brace
            if (verboseLevel >= 1) System.out.println("  e2v = "+VecMath.toString(e2v));
            if (verboseLevel >= 1) System.out.println("  v2e = "+VecMath.toString(v2e));
            if (verboseLevel >= 1) System.out.println("  undirectedEdgeIsInSpanningTree = "+VecMath.toString(undirectedEdgeIsInSpanningTree));
            int nVerts = this.v2e.length;
            int vertToParentEdgeOut[] = VecMath.fillvec(nVerts, -1);
            int queue[] = new int[nVerts];
            int queueSize = 0;
            queue[queueSize++] = root;
            while (queueSize > 0)
            {
                int iVert = queue[--queueSize];
                int edgesOut[] = this.v2e[iVert];
                FORI (iEdgeOut, edgesOut.length)
                {
                    int iEdge = edgesOut[iEdgeOut];
                    if (iEdge != vertToParentEdgeOut[iVert] // i.e. if didn't just come from there
                     && undirectedEdgeIsInSpanningTree[iEdge/2])
                    {
                        assert(this.e2v[iEdge][0] == iVert);
                        int jVert = this.e2v[iEdge][1];
                        int parentEdgeOut = iEdge ^ 1; // opposite edge
                        vertToParentEdgeOut[jVert] = parentEdgeOut;
                        assert(this.e2v[parentEdgeOut][0] == jVert);
                        assert(this.e2v[parentEdgeOut][1] == iVert);
                        queue[queueSize++] = jVert;
                    }
                }
            }
            if (verboseLevel >= 1) System.out.println("  vertToParentEdgeOut = "+Arrays.toStringCompact(vertToParentEdgeOut));
            if (verboseLevel >= 1) System.out.println("out getVertToParentEdgeOut");
            return vertToParentEdgeOut;
        } // getVertToParent
    } // SimplerMeshDataStructure

    // See paper "Generating Random Spanning Trees
    // More Quickly than the Cover Time" by David Bruce Wilson.
    // But, can't I do it in O(n) time,
    // by simply growing the tree and picking a random new edge out of it on every step?
    // (answer: no, the next edge out of the spanning tree can't be picked uniformly)
    // Verify that Wilson's algorithm gives something uniformly random,
    // or that the more well known random walk one does,
    // or that a similar one doesn't.
    // Note: This doesn't really do anything useful, it just prints stats, with method
    // chosen via hard-coded true/false's in the code below.
    public static void analyzeRandomSpanningTrees(Mesh mesh)
    {
        System.out.println("    in analyzeRandomSpanningTrees");
        int nEdges = mesh.edges.size();
        PRINT(nEdges);
        if (nEdges > 26) // i.e. 13 undirected.
        {
            System.out.println("      too many edges, bailing");
            System.out.println("    out analyzeRandomSpanningTrees");
            return;
        }

        SimplerMeshDataStructure simplerMeshDataStructure = new SimplerMeshDataStructure(mesh, true);
        if (!simplerMeshDataStructure.isConnectedExceptMaybeForIsolatedVerts())
        {
            System.out.println("      graph is disconnected; bailing");
            System.out.println("    out analyzeRandomSpanningTrees");
            return;
        }

        java.util.Random generator = new java.util.Random();

        int counts[] = new int[1<<nEdges];

        int nTries = 1000*1000;
        FORI (iTry, nTries)
        {
            // Make a random spanning tree, and increment its count.

            int whichTree;

            if (true)
            {
                // Wilson's algorithm.
                boolean answer[] = simplerMeshDataStructure.randomSpanningTree(generator);
                whichTree = 0;
                FORI (iUndirectedEdge, answer.length)
                    if (answer[iUndirectedEdge])
                        whichTree |= (1 << iUndirectedEdge);
            }
            else if (false)
            {
                // random walk from 0,
                // keeping *last* edge to each new vertex.
                // This apparently isn't uniform!

                int e2v[][] = simplerMeshDataStructure.e2v;
                int v2e[][] = simplerMeshDataStructure.v2e;
                int nVerts = v2e.length; // may be 1 more than mesh.verts.size(). CBB: error prone!

                boolean inTree[] = new boolean[nVerts]; // false initially
                int prev[] = VecMath.fillvec(nVerts, -1); // vertex to prev *edge*, not vertex
                int r = 0; // arbitrarily

                inTree[r] = true;
                int nVertsInTree = 1;
                int u = r;
                while (nVertsInTree < nVerts)
                {
                    int iEdge = v2e[u][generator.nextInt(v2e[u].length)];
                    u = e2v[iEdge][1];
                    prev[u] = iEdge; // clobber old value if any, so we retain last edge to u
                    if (!inTree[u])
                    {
                        inTree[u] = true;
                        nVertsInTree++;
                    }
                }

                whichTree = 0;
                FORI (iVert, nVerts)
                {
                    int iEdge = prev[iVert];
                    if (iEdge != -1)
                    {
                        whichTree |= (1 << (iEdge/2));
                    }
                }
            }
            else if (false)
            {
                // random walk from 0,
                // keeping *first* edge to each new vertex.
                // This seems to be uniform.
                // (and takes cover time, I think?)

                int e2v[][] = simplerMeshDataStructure.e2v;
                int v2e[][] = simplerMeshDataStructure.v2e;
                int nVerts = v2e.length; // may be 1 more than mesh.verts.size(). CBB: error prone!

                boolean inTree[] = new boolean[nVerts]; // false initially
                int prev[] = VecMath.fillvec(nVerts, -1); // vertex to prev *edge*, not vertex
                int r = 0; // arbitrarily

                inTree[r] = true;
                int nVertsInTree = 1;
                int u = r;
                while (nVertsInTree < nVerts)
                {
                    int iEdge = v2e[u][generator.nextInt(v2e[u].length)];
                    u = e2v[iEdge][1];
                    if (!inTree[u])
                    {
                        prev[u] = iEdge; // only record first edge to u
                        inTree[u] = true;
                        nVertsInTree++;
                    }
                }

                whichTree = 0;
                FORI (iVert, nVerts)
                {
                    int iEdge = prev[iVert];
                    if (iEdge != -1)
                    {
                        whichTree |= (1 << (iEdge/2));
                    }
                }
            }
            else
            {
                assert(false);
            }

            //PRINT(whichTree);

            counts[whichTree]++;
        }
        //PRINTARRAY(counts);

        SortStuff.sort(counts);
        int nZeros = 0;
        while (nZeros < counts.length && counts[nZeros] == 0)
            nZeros++;
        counts = (int[])Arrays.subarray(counts, nZeros, counts.length-nZeros);
        PRINTARRAY(counts);
        PRINT(counts.length);

        System.out.println("    out analyzeRandomSpanningTrees");
    } // analyzeRandomSpanningTrees

    // I seem to have set the bar too high on using VecMath for this... make private utility function instead
    private static double[] v3xm44(double v[/*3*/], double m[/*4*/][/*4*/])
    {
        int three = v.length;
        assert_eq(m.length, three+1);
        assert_eq(m[0].length, three+1);
        double scratch[] = Arrays.append(v, 1.);
        scratch = VecMath.vxm(scratch, m);
        if (scratch[three] == 1.)
            return (double[])Arrays.subarray(scratch, 0, three);
        else
            return VecMath.vxs(three, scratch, scratch[three]);
    }

    public static Mesh.Vertex[] findAllVertsThatAreImages(Mesh mesh, double v[/*2*/], double group[][/*2*/][/*2*/], double tol)
    {
        int nVerts = mesh.verts.size();
        boolean foundVert[] = new boolean[nVerts];
        int nFound = 0;
        FORI (iGroup, group.length)
        {
            assert_eq(v.length, 3);
            double image[] = v3xm44(v,group[iGroup]);
            assert_eq(image.length, 3);
            FORI (iVert, nVerts)
            {
                if (!foundVert[iVert])
                {
                    Mesh.Vertex vertI = mesh.getVert(iVert);
                    // TODO: compute in homo
                    if (EQ(image[0], vertI.x(), tol)
                     && EQ(image[1], vertI.y(), tol)
                     && EQ(image[2], vertI.z(), tol))
                    {
                        foundVert[iVert] = true;
                        nFound++;
                    }
                }
            }
        }
        Mesh.Vertex answer[] = new Mesh.Vertex[nFound];
        nFound = 0;
        FORI (iVert, nVerts)
            if (foundVert[iVert])
                answer[nFound++] = mesh.getVert(iVert);
        assert_eq(nFound, answer.length);
        return answer;
    } // findAllVertsThatAreImages

    // TODO: move these to VecMath I think
    // Normalize so max abs value of coordinates is 1.
    private static void homoNormalize(int n, double answer[], double v[])
    {
        double divideByThis = ABS(v[0]);
        for (int i = 1; i < n; ++i) // skip 0
        {
            double absvi = ABS(v[i]);
            divideByThis = MAX(divideByThis, absvi);
        }
        VecMath.vxs(n, answer, v, 1./divideByThis);
    }
    private static void homoNormalize(double answer[], double v[])
    {
        homoNormalize(MIN(answer.length,v.length), answer, v);
    }
    private static double[] homoNormalize(double v[])
    {
        double answer[] = new double[v.length];
        homoNormalize(v.length, answer, v);
        return answer;
    }

    // Might or might not return the same mesh.
    public static Mesh forceMeshSymmetryByDeletingVertsDestructive(Mesh mesh, double group[][][], boolean retainConnectivity)
    {
        System.out.println("    in forceMeshSymmetryByDeletingVertsDestructive");
        int nVerts = mesh.verts.size();
        System.out.println("          nVerts = "+nVerts);
        double vertsHomo[][] = new double[nVerts][4];
        FORI (iVert, nVerts)
        {
            Mesh.Vertex vert = mesh.getVert(iVert);
            vertsHomo[iVert][0] = vert.X();
            vertsHomo[iVert][1] = vert.Y();
            vertsHomo[iVert][2] = vert.Z();
            vertsHomo[iVert][3] = vert.W();
        }

        // as recommended in FuzzyPointHashTable doc...
        FuzzyPointHashTable fuzzyTable = new FuzzyPointHashTable(1e-12, 1e-10, 1/1024.);
        Object dummy = new Object(); // we really want a hash set, not hash table, so need a dummy object, distinct from null

        // Initial pass adding originals, since those are the preferred images
        FORI (iVert, nVerts)
        {
            if (fuzzyTable.put(homoNormalize(vertsHomo[iVert]),dummy) == null) // i.e. if it wasn't already there
            {
                // nothing. we don't dedup here (although maybe we should).
            }
        }
        // Retain only verts in vertsHomo that are "all there".
        // CBB: probably theres a more efficient algorithm; whatever
        boolean bad[] = new boolean[nVerts];
        int nBad = 0;
        {
            double scratchHomo[] = new double[4];
            double scratchHomoNormalized[] = new double[4];
            FORI (iVert, nVerts)
            {
                for (int iSymmetry = 1; iSymmetry < group.length; ++iSymmetry) // skip 0 since we did it already
                {
                    VecMath.vxm(scratchHomo, vertsHomo[iVert], group[iSymmetry]);
                    homoNormalize(scratchHomoNormalized, scratchHomo);
                    if (fuzzyTable.get(scratchHomoNormalized) == null)
                    {
                        bad[iVert] = true;
                        nBad++;
                        break;
                    }
                }
            }
        }
        if (nBad == 0)
        {
            System.out.println("    out forceMeshSymmetryByDeletingVertsDestructive (nothing changed in "+nVerts+" verts)");
            return mesh;
        }
        if (retainConnectivity)
        {
            // Note, each removal takes O(n) time, so this is quadratic.
            FORIDOWN(iVert, nVerts) // backwards so that deleting won't mess up indices of future work
            {
                if (bad[iVert])
                {
                    mesh.deleteVertex(mesh.getVert(iVert), null, null);
                }
            }
            System.out.println("    out forceMeshSymmetryByDeletingVertsDestructive (deleted "+nBad+"/"+nVerts+" verts in place))");
            return mesh;
        }
        else
        {
            double goodVerts[][] = new double[nVerts-nBad][];
            int nGood = 0;
            FORI (iVert, nVerts)
                if (!bad[iVert])
                    goodVerts[nGood++] = vertsHomo[iVert];
            assert(nGood == goodVerts.length);
            Mesh answer = new Mesh(goodVerts, new int[0][]);
            System.out.println("    out forceMeshSymmetryByDeletingVertsDestructive (created new mesh to delete "+nBad+"/"+nVerts+" verts)");
            return answer;
        }
    } // forceMeshSymmetryByDeletingVertsDestructive

    // Currently destroys connectivity. Another option would be to add verts one by one, the same as if user created them.
    // Currently removes dups.
    // CBB: should vert store notion of whether the intent was H or W?  we assume W.
    // NOTE: I'm using normalized homogeneous coords as keys... however, the reason I'm doing that is because I thought it would fix the behavior on "crack goes in spiral small", but it doesn't!  so maybe go back to using 3d points?  Not sure.  Normalized homo does have the advantage that it should do something reasonable with very large coords though.  Hmm.
    public static Mesh forceMeshSymmetryByReplicatingVerts(Mesh mesh, double group[][][])
    {
        System.out.println("    in forceMeshSymmetryByReplicatingVerts");
        int nVerts = mesh.verts.size();
        System.out.println("          nVerts = "+nVerts);
        double vertsHomo[][] = new double[nVerts][4];
        FORI (iVert, nVerts)
        {
            Mesh.Vertex vert = mesh.getVert(iVert);
            vertsHomo[iVert][0] = vert.X();
            vertsHomo[iVert][1] = vert.Y();
            vertsHomo[iVert][2] = vert.Z();
            vertsHomo[iVert][3] = vert.W();
        }

        // as recommended in FuzzyPointHashTable doc...
        FuzzyPointHashTable fuzzyTable = new FuzzyPointHashTable(1e-12, 1e-10, 1/1024.);
        Object dummy = new Object(); // we really want a hash set, not hash table, so need a dummy object, distinct from null

        ArrayList/*<double[]>*/ finalVertsArrayList = new ArrayList();

        // Initial pass adding originals, since those are the preferred images
        FORI (iVert, nVerts)
        {
            if (fuzzyTable.put(homoNormalize(vertsHomo[iVert]),dummy) == null) // i.e. if it wasn't already there
                finalVertsArrayList.add(vertsHomo[iVert]);
        }
        double scratchHomo[] = new double[4];
        FORI (iVert, nVerts)
        {
            for (int iSymmetry = 1; iSymmetry < group.length; ++iSymmetry) // skip 0 since we did it already
            {
                VecMath.vxm(scratchHomo, vertsHomo[iVert], group[iSymmetry]);
                if (fuzzyTable.put(homoNormalize(scratchHomo),dummy) == null) // i.e. if it wasn't already there
                    finalVertsArrayList.add(VecMath.copyvec(scratchHomo));
            }
        }
        double finalVerts[][] = new double[finalVertsArrayList.size()][4];
        finalVertsArrayList.toArray(finalVerts);
        finalVertsArrayList = null;

        Mesh answer = new Mesh(finalVerts, new int[0][]);

        System.out.println("    out forceMeshSymmetryByReplicatingVerts");
        return answer;

    } // forceMeshSymmetryByReplicatingVerts

    public static Mesh changeMeshRotationalSymmetry(Mesh mesh,
                                                    int oldP, int oldQ,
                                                    int newP, int newQ)
    {
        System.out.println("    in changeMeshRotationalSymmetry");
        ArrayList/*<double[]>*/ newVertsArrayList = new ArrayList();

        if (oldQ == 1 && newQ == 1)
        {
            // Old and new fundamental regions are infinite pie slices
            System.out.println("      remap fundamental region pie slice");

            int nOldVerts = mesh.verts.size();
            System.out.println("          nOldVerts = "+nOldVerts);
            double oldVerts[][] = new double[nOldVerts][3];
            FORI (iOldVert, nOldVerts)
            {
                Mesh.Vertex vert = mesh.getVert(iOldVert);
                oldVerts[iOldVert][0] = vert.x();
                oldVerts[iOldVert][1] = vert.y();
                oldVerts[iOldVert][2] = vert.h(); // different from the other (hmm, should this be dependent on wrapAroundSphere instead? now I'm confused)
            }
            double oldBbox[][] = VecMath.bbox(oldVerts);
            double workAreaSize = (nOldVerts==0 ? 1. : MAX4(ABS(oldBbox[0][0]),
                                                            ABS(oldBbox[0][1]),
                                                            ABS(oldBbox[1][0]),
                                                            ABS(oldBbox[1][1])));

            // as recommended in FuzzyPointHashTable doc...
            double littleTol = 1e-12 * workAreaSize;
            double bigTol = 1e-10 * workAreaSize;
            double bucketSize = 1/1024. * workAreaSize;
            FuzzyPointHashTable newVertsTable = new FuzzyPointHashTable(littleTol,
                                                                        bigTol,
                                                                        bucketSize);
            Object dummy = new Object(); // we really want a hash set, not hash table, so need a dummy object, distinct from null

            FORI (iOldVert, nOldVerts)
            {
                double oldVert[] = oldVerts[iOldVert];
                double magnitude = MyMath.hypot(oldVert[0], oldVert[1]);
                double oldAngle = Math.atan2(oldVert[1], oldVert[0]);
                // find fraction in the canonical fundamental region...
                double frac = (oldAngle/(2*Math.PI) + .25) // so -90 degrees produces frac=0
                            * oldP;
                frac -= Math.floor(frac); // so frac should now be between 0 and 1

                if (false) // nah, this looks like hell
                {
                    // make it a conformal mapping (raising to a power in the complex plane)...
                    magnitude = Math.pow(magnitude, (double)oldP/(double)newP);
                }

                FORI (iNewImage, newP)
                {
                    double newAngle = (((iNewImage+frac)) / newP - .25) * (2*Math.PI);
                    double newVert[] = {
                        magnitude * Math.cos(newAngle),
                        magnitude * Math.sin(newAngle),
                    };
                    if (newVertsTable.put(newVert,dummy) == null) // i.e. if it wasn't already there
                    {
                        newVertsArrayList.add(new double[] {
                            newVert[0],
                            newVert[1],
                            oldVert[2], // takes one of the old heights arbitrarily, if multiple.  CBB: can we set it to average?
                        });
                    }
                }
            }
        } else if (oldP != 1 && oldQ != 1
                && newP != 1 && newQ != 1)
        {
            // Old and new fundamental regions are triangles.  Or something.
            System.out.println("      remap fundamental region quad");

            int nOldVerts = mesh.verts.size();
            System.out.println("          nOldVerts = "+nOldVerts);
            double oldVerts[][] = new double[nOldVerts][3];
            FORI (iOldVert, nOldVerts)
            {
                Mesh.Vertex vert = mesh.getVert(iOldVert);
                oldVerts[iOldVert][0] = vert.x();
                oldVerts[iOldVert][1] = vert.y();
                oldVerts[iOldVert][2] = vert.z(); // different from the other  (hmm, should this be dependent on wrapAroundSphere instead? now I'm confused)
            }
            double oldBbox[][] = VecMath.bbox(oldVerts);
            double workAreaSize = (nOldVerts==0 ? 1. : MAX4(ABS(oldBbox[0][0]),
                                                            ABS(oldBbox[0][1]),
                                                            ABS(oldBbox[1][0]),
                                                            ABS(oldBbox[1][1])));


            double oldGroup[][][] = SymmetryUtils.computeSymmetryGroup3d(
                oldP,
                oldQ,
                false, false, // no reflections taken into account here
                false); // repeat work-in-progress not taken into account here, yet

            System.out.println("          "+oldGroup.length+" old symmetries");

            double oldFundamentalRegionVerts[][] = SymmetryUtils.getFundamentalRegionVerts(oldP, oldQ, false);
            int gonality = oldFundamentalRegionVerts.length;
            assert(gonality == 4); // because no reflections
            double oldFundamentalRegionInwardNormals[][] = new double[gonality][3];
            FORI (i, gonality)
            {
                VecMath.vxv3(oldFundamentalRegionInwardNormals[i],
                             oldFundamentalRegionVerts[i],
                             oldFundamentalRegionVerts[(i+1)%gonality]);
                VecMath.normalize(oldFundamentalRegionInwardNormals[i],
                                  oldFundamentalRegionInwardNormals[i]);
            }

            double oldImages[][] = new double[nOldVerts][3];
            {
                double oldImage[] = new double[3]; // scratch for loop
                double fakeBary[] = new double[gonality]; // scratch for loop

                FORI (iOldVert, nOldVerts)
                {
                    double oldVert[] = oldVerts[iOldVert];

                    // Which symmetry brings it into old fundamental region?
                    // It's fuzzy, so make it a contest.
                    double bestGoodness = Double.NEGATIVE_INFINITY;
                    FORI (iOldSymmetry, oldGroup.length)
                    {
                        // CBB: could premultiply the two matrices together, i.e. precompute all images of schwarz triangles. would be less work if lots of oldVerts.
                        VecMath.vxm(oldImage, oldVert, oldGroup[iOldSymmetry]);
                        VecMath.mxv(fakeBary, oldFundamentalRegionInwardNormals, oldImage);
                        double goodness = VecMath.min(fakeBary);
                        if (goodness > bestGoodness)
                        {
                            bestGoodness = goodness;
                            VecMath.copyvec(oldImages[iOldVert], oldImage);
                        }
                    }
                }
            }
            if (true)
            {
                // De-dup oldImages.
                // Note that there can actually still be dups, for images on the boundary of the fundamental region
                // when not reflective symmetry,
                // but comparatively few of them and we'll catch those later.
                // TODO: make a utility function out of deduping?
                int nDeDuped = 0;
                {
                    // TODO: make a FuzzyPointHashSet that does this?

                    Object dummy = new Object(); // we really want a hash set, not hash table, so need a dummy object, distinct from null
                    // as recommended in FuzzyPointHashTable doc...
                    double littleTol = 1e-12 * workAreaSize;
                    double bigTol = 1e-10 * workAreaSize;
                    double bucketSize = 1/1024. * workAreaSize;
                    FuzzyPointHashTable newVertsTable = new FuzzyPointHashTable(littleTol,
                                                                                bigTol,
                                                                                bucketSize);
                    FuzzyPointHashTable fuzzyPointHashTable = new FuzzyPointHashTable(littleTol, bigTol, bucketSize);
                    FORI (iOldVert, nOldVerts)
                        if (newVertsTable.put(oldImages[iOldVert],dummy) == null) // i.e. if it wasn't already there
                            VecMath.copyvec(oldImages[nDeDuped++], oldImages[iOldVert]);
                }
                System.out.println("          old images deduped "+oldImages.length+" -> "+nDeDuped);
                oldImages = (double[][])Arrays.subarray(oldImages, 0, nDeDuped);
            }

            double newImages[][] = new double[oldImages.length][3];

            double newFundamentalRegionVerts[][] = SymmetryUtils.getFundamentalRegionVerts(newP, newQ, false);
            assert(newFundamentalRegionVerts.length == gonality);
            if (gonality == 3)
            {
                assert(false); // it turns out we only do this with rotational symmetry, so this doesn't happen
                double bary[] = new double[3]; // scratch for loop
                FORI (iImage, oldImages.length)
                {
                    double oldMagnitude = VecMath.normalize(oldImages[iImage],oldImages[iImage]); // destructive
                    VecMath.getSphericalAverageWeights(bary, oldFundamentalRegionVerts, oldImages[iImage]);
                    VecMath.sphericalAverage(newImages[iImage], newFundamentalRegionVerts, bary);
                    VecMath.vxs(newImages[iImage], newImages[iImage], oldMagnitude);
                }
            }
            else // gonality == 4
            {
                double oldTris[/*2*/][/*3*/][/*3*/] = {
                    {oldFundamentalRegionVerts[0],oldFundamentalRegionVerts[1],oldFundamentalRegionVerts[2]},
                    {oldFundamentalRegionVerts[0],oldFundamentalRegionVerts[2],oldFundamentalRegionVerts[3]},
                };
                double newTris[/*2*/][/*3*/][/*3*/] = {
                    {newFundamentalRegionVerts[0],newFundamentalRegionVerts[1],newFundamentalRegionVerts[2]},
                    {newFundamentalRegionVerts[0],newFundamentalRegionVerts[2],newFundamentalRegionVerts[3]},
                };
                double bary[] = new double[3]; // scratch for loop
                FORI (iImage, oldImages.length)
                {
                    int which = oldImages[iImage][0]>=0 ? 0 : 1;
                    double oldMagnitude = VecMath.normalize(oldImages[iImage],oldImages[iImage]); // destructive
                    VecMath.getSphericalAverageWeights(bary, oldTris[which], oldImages[iImage]);
                    VecMath.sphericalAverage(newImages[iImage], newTris[which], bary);
                    VecMath.vxs(newImages[iImage], newImages[iImage], oldMagnitude);
                }
            }

            double newGroup[][][] = SymmetryUtils.computeSymmetryGroup3d(
                newP,
                newQ,
                false, false, // no reflections taken into account here
                false); // repeat work-in-progress not taken into account here, yet
            System.out.println("          "+newGroup.length+" new symmetries");
            {
                Object dummy = new Object(); // we really want a hash set, not hash table, so need a dummy object, distinct from null
                // as recommended in FuzzyPointHashTable doc...
                double littleTol = 1e-12 * workAreaSize;
                double bigTol = 1e-10 * workAreaSize;
                double bucketSize = 1/1024. * workAreaSize;
                FuzzyPointHashTable newVertsTable = new FuzzyPointHashTable(littleTol,
                                                                            bigTol,
                                                                            bucketSize);
                double newVert[] = new double[3]; // scratch for loop
                // CBB: probably theres a more efficient algorithm; whatever
                FORI (iImage, newImages.length)
                {
                    FORI (iNewSymmetry, newGroup.length)
                    {
                        VecMath.vxm(newVert, newImages[iImage], newGroup[iNewSymmetry]);
                        if (newVertsTable.put(newVert,dummy) == null) // i.e. if it wasn't already there
                            newVertsArrayList.add(Arrays.append(newVert, 1.)); // xyzw (otherwise would be interpreted as xyh)
                    }
                }
                System.out.println("          new verts deduped "+(newImages.length*newGroup.length)+" -> "+newVertsArrayList.size());
            }

            if (false)
            {
                // HACK-- show the new fundamental region verts
                FORI (i, newFundamentalRegionVerts.length)
                    newVertsArrayList.add(Arrays.append(newFundamentalRegionVerts[i], 1.));
            }
            if (false)
            {
                // HACK-- show old images
                FORI (i, oldImages.length)
                    newVertsArrayList.add(Arrays.append(oldImages[i], 1.));
            }
            if (false)
            {
                // HACK-- show new images
                FORI (i, oldImages.length)
                    newVertsArrayList.add(Arrays.append(newImages[i], 1.));
            }
        }

        double newVerts[][] = new double[newVertsArrayList.size()][];
        newVertsArrayList.toArray(newVerts);
        newVertsArrayList = null;

        // For now, don't try to retain any connectivity.
        // A mesh will appear if "Keep delaunayized" is checked.
        Mesh answer = new Mesh(newVerts, new int[0][]);

        System.out.println("    out changeMeshRotationalSymmetry");
        return answer;
    } // changeMeshRotationalSymmetry

    public static final int FACING_UNKNOWN = 0;
    public static final int FACING_BACK = 1;
    public static final int FACING_SIDE = 2;
    public static final int FACING_FRONT = 3;
    public static void getFacings(double eyeInLocalSpace[],
                                  Mesh mesh, Mesh dualMesh, boolean meshIsReallyDualMesh,
                                  int faceFacings[],
                                  int edgeFacings[],
                                  int vertFacings[],
                                  boolean wrapAroundSphereFlagValue,
                                  boolean centerSphereFlagValue,
                                  double wrapSphereCurvatureValue)
    {
        int verboseLevel = 0;
        if (verboseLevel >= 1) System.out.println("    in getFacings");
        VecMath.fillvec(faceFacings, FACING_UNKNOWN);
        VecMath.fillvec(edgeFacings, FACING_UNKNOWN);
        VecMath.fillvec(vertFacings, FACING_UNKNOWN);

        // XXX wait, is there some confusion here? aren't some of the array sizes one more than this?
        int nVerts = mesh.verts.size();
        int nEdges = mesh.edges.size();
        int nDualVerts = dualMesh.verts.size();

        if (verboseLevel >= 1) System.out.println("      eyeInLocalSpace = "+VecMath.toString(eyeInLocalSpace));
        // compute face facings...
        if (verboseLevel >= 1) System.out.println("      computing face facings");


        // TODO: Do I need to abandon this first method??
        // Problem is, in wrapped-around-sphere case, if whole polyhedron is eyeward of the origin, it's impossible
        // to tell direction from 3d dual vertex position.
        // However, for paraboloid case, it's awesome!  It magically gives the right answer given dual vertex, although I don't understand why.
        if (false)
        {
            FORI (iFace, nDualVerts)
            {
                Mesh.Vertex dualVert = dualMesh.getVert(iFace);

                // plane is all points p such that p dot facePlaneNormal == facePlaneOffset

                double facePlaneNormal[];
                double facePlaneOffset;

                if (wrapAroundSphereFlagValue)
                {
                    // reciprocated wrt sphere.

                    // just work with frickin actual coords,
                    // homogeneous coords are too confusing
                    // and w=0 is exceedingly rare in wrapped-around-sphere case anyway.
                    // this is STILL too frickin complicated!

                    facePlaneNormal = new double[] {
                        dualVert.x(),
                        dualVert.y(),
                        centerSphereFlagValue ? dualVert.z() : dualVert.z() + 1./wrapSphereCurvatureValue
                    };
                    double dualVertDist2FromCenter = VecMath.normsqrd(facePlaneNormal);
                    double facePlaneSmallestPoint[] = VecMath.vxs(facePlaneNormal, 1./dualVertDist2FromCenter);
                    if (!centerSphereFlagValue)
                        facePlaneSmallestPoint[2] -= 1./wrapSphereCurvatureValue;
                    facePlaneOffset = VecMath.dot(facePlaneNormal, facePlaneSmallestPoint);

                    // Hmm, that's wrong if face plane is facing the origin...
                    // and useless if the face plane passes through the origin (in which case the dual vert is at infinity).
                    // How the heck can we tell??
                }
                else
                {
                    // reciprocated wrt paraboloid
                    facePlaneNormal = new double[] {dualVert.X(), dualVert.Y(), dualVert.W()}; // i.e. x,y,1.  not unit length.
                    facePlaneOffset = -dualVert.Z(); // i.e. z.  magic!  I don't know why, but this is the correct value
                }
                // XXX not sure the epsilons make sense... maybe normalize facePlaneNormal and offset, just so we can think straight about that?
                double frontness = VecMath.dot(facePlaneNormal, eyeInLocalSpace)
                          - facePlaneOffset;
                if (LT(frontness, 0., SQR(1e-6)))
                    faceFacings[iFace] = FACING_BACK;
                else if (GT(frontness, 0., SQR(1e-6)))
                    faceFacings[iFace] = FACING_FRONT;
                else
                    faceFacings[iFace] = FACING_SIDE;
            }
        }
        else
        {
            if (verboseLevel >= 1) System.out.println("          (NOT!)");
        }

        // Bleah, the faces that don't have dual verts
        // need to be computed by a separate method.
        // (and the above method sucks anyway, at least for wrapped-around-sphere).
        if (verboseLevel >= 1) System.out.println("      computing face for faces that don't have dual verts");
        FORI (iEdge, nEdges)
        {
            Mesh.Edge edgeI = mesh.getEdge(iEdge);
            Mesh.Edge dualEdgeI = dualMesh.getEdge(iEdge);
            Mesh.Vertex leftDualVert = dualEdgeI.finalVertex();
            int iLeftFace = leftDualVert==null ? nDualVerts : leftDualVert.myIndex();
            if (faceFacings[iLeftFace] == FACING_UNKNOWN)
            {
                if (verboseLevel >= 2) System.out.println("          iEdge = e"+iEdge+"/"+nEdges+" "+(edgeI.initialVertex()==null?"null":"v"+edgeI.initialVertex().myIndex())+"->"+(edgeI.finalVertex()==null?"null  ":"v"+edgeI.finalVertex().myIndex())+" ("+(edgeI.direction!=null?"has direction":"no direction")+")");
                double normal[] = {0,0,0}; // for starters
                double moment[] = {0,0,0}; // for starters
                double centroid[] = null;
                // XXX TODO: centroid of verts might be more robust than area centroid? yeah I think so, hmm
                double area = 0.;
                {
                    Mesh.Vertex v0 = edgeI.initialVertex();
                    if (v0 == null)
                    {
                        if (verboseLevel >= 2) System.out.println("              ouch! edge "+iEdge+" has null initial vertex ("+(edgeI.direction!=null?"has direction":"no direction")+")");
                        // This one shouldn't be a disaster; this face will be solved by some other edge on it.
                        continue;
                    }
                    // CBB: compute in homogeneous space?  Hmm that would be ambitious.
                    assert(v0 != null);
                    double v0coords[] = {v0.x(), v0.y(), v0.z()};
                    double v1coords[] = new double[3]; // scratch for loop
                    double v2coords[] = new double[3]; // scratch for loop
                    double thisCentroid[] = new double[3]; // scratch for loop
                    double thisWeightedNormal[] = new double[3]; // scratch for loop
                    Mesh.Edge edgeJ;
                    for (edgeJ = edgeI.next(); edgeJ.next() != edgeI; edgeJ = edgeJ.next())
                    {
                        Mesh.Vertex v1 = edgeJ.initialVertex();
                        Mesh.Vertex v2 = edgeJ.finalVertex();
                        // a bit hackish, but prevents weird computation using vertices we shouldn't be using
                        if (v1 != null && v1.weight < 0.) v1 = null;
                        if (v2 != null && v2.weight < 0.) v2 = null;
                        if (v1 == null && v2 == null)
                        {
                            // Happens when not "calc underside when delaunayizing"
                            // Not quite sure yet how to prevent these things from being drawn.  (e.g. the second sheet, when convex noise 1 starts from a square and I don't re-delaunayize with "calc underside when delaunayizing"=false at end)
                            if (verboseLevel >= 0) System.out.println("                  ouch! edge "+edgeJ.myIndex()+" has null initial and final vertex ("+(edgeJ.direction!=null?"has direction":"no direction")+")");
                            break;
                        }
                        else if (v1 == null)
                        {
                            if (verboseLevel >= 2) System.out.println("                  ouch! edge "+edgeJ.myIndex()+" has null initial vertex ("+(edgeJ.direction!=null?"has direction":"no direction")+")");
                            assert(edgeJ.direction != null);
                            v2coords[0] = v2.x();
                            v2coords[1] = v2.y();
                            v2coords[2] = v2.z();
                            VecMath.vmv(3, v1coords, v2coords, edgeJ.direction);
                        }
                        else if (v2 == null)
                        {
                            if (verboseLevel >= 2) System.out.println("                  ouch! edge "+edgeJ.myIndex()+" has null final vertex ("+(edgeJ.direction!=null?"has direction":"no direction")+")");
                            assert(edgeJ.direction != null);
                            v1coords[0] = v1.x();
                            v1coords[1] = v1.y();
                            v1coords[2] = v1.z();
                            VecMath.vpv(3, v2coords, v1coords, edgeJ.direction);
                        }
                        else
                        {
                            v1coords[0] = v1.x();
                            v1coords[1] = v1.y();
                            v1coords[2] = v1.z();
                            v2coords[0] = v2.x();
                            v2coords[1] = v2.y();
                            v2coords[2] = v2.z();
                        }
                        VecMath.vmv(v1coords, v1coords, v0coords); // so now relative to v0
                        VecMath.vmv(v2coords, v2coords, v0coords); // so now relative to v0
                        VecMath.vxv3(thisWeightedNormal, v1coords, v2coords);
                        VecMath.vpv(normal, normal, thisWeightedNormal);
                        if (verboseLevel >= 2) System.out.println("                  jEdge = e"+edgeJ.myIndex()+"/"+nEdges+" "+(edgeJ.initialVertex()==null?"null":"v"+edgeJ.initialVertex().myIndex())+"->"+(edgeJ.finalVertex()==null?"null  ":"v"+edgeJ.finalVertex().myIndex())+" adding weighted normal "+VecMath.toString(thisWeightedNormal));
                        double thisArea = VecMath.norm(thisWeightedNormal);
                        area += thisArea;
                        VecMath.sxvpsxv(thisCentroid, 1/3., v1coords, 1/3., v2coords); // relative to v0
                        VecMath.vpsxv(moment, moment, thisArea, thisCentroid);
                    }
                    if (edgeJ != edgeI) // if broke
                    {
                        if (verboseLevel >= 2) System.out.println("              ouch! continuing");
                    }
                    centroid = VecMath.vpsxv(v0coords, 1./area, moment);
                }
                if (verboseLevel >= 2) System.out.println("              normal = "+VecMath.toString(normal));
                if (verboseLevel >= 2) System.out.println("              eyeInLocalSpace-centroid = "+VecMath.toString(VecMath.vmv(eyeInLocalSpace, centroid)));
                double frontness = VecMath.dot(normal, eyeInLocalSpace)
                                 - VecMath.dot(normal, centroid);
                if (meshIsReallyDualMesh)
                    frontness *= -1;
                if (verboseLevel >= 2) System.out.println("              frontness = "+frontness);
                // XXX not sure the epsilons make sense... maybe normalize normal, just so we can think straight about that?
                if (LT(frontness, 0., SQR(1e-6)))
                    faceFacings[iLeftFace] = FACING_BACK;
                else if (GT(frontness, 0., SQR(1e-6)))
                    faceFacings[iLeftFace] = FACING_FRONT;
                else
                    faceFacings[iLeftFace] = FACING_SIDE;
                //PRINTVEC(normal);
            }
        }

        // TODO: explain exactly what UNKNOWN in faceFacings means
        if (verboseLevel >= 2)
        {
            FORI (i, faceFacings.length)
                if (faceFacings[i] == FACING_UNKNOWN)
                    OUT("HEY! faceFacings["+i+"/"+faceFacings.length+"] is UNKNOWN!");
        }

        // compute edge facings from incident face facings...
        if (verboseLevel >= 1) System.out.println("      computing edge facings");
        FORI (iEdge, nEdges)
        {
            if (edgeFacings[iEdge] == FACING_UNKNOWN)
            {
                Mesh.Edge edgeI = mesh.getEdge(iEdge);
                Mesh.Edge dualEdgeI = dualMesh.getEdge(iEdge);
                Mesh.Vertex leftDualVert = dualEdgeI.finalVertex();
                Mesh.Vertex rightDualVert = dualEdgeI.initialVertex();
                int iLeftFace = leftDualVert==null ? nDualVerts : leftDualVert.myIndex();
                int iRightFace = rightDualVert==null ? nDualVerts : rightDualVert.myIndex();
                int leftFaceFacing = faceFacings[iLeftFace];
                int rightFaceFacing = faceFacings[iRightFace];
                // UNKNOWN trumps all others
                edgeFacings[iEdge] = (leftFaceFacing==FACING_UNKNOWN || rightFaceFacing==FACING_UNKNOWN) ? FACING_UNKNOWN
                                   : leftFaceFacing==rightFaceFacing ? leftFaceFacing
                                   : FACING_SIDE;
                int oEdge = edgeI.opposite().myIndex();
                assert(oEdge == (iEdge^1));
                edgeFacings[oEdge] = edgeFacings[iEdge];
            }
        }

        // TODO: explain exactly what UNKNOWN in edgeFacings means
        if (verboseLevel >= 2)
        {
            FORI (i, edgeFacings.length)
                if (edgeFacings[i] == FACING_UNKNOWN)
                    OUT("HEY! edgeFacings["+i+"/"+edgeFacings.length+"] is UNKNOWN!");
        }

        // compute vert facings from incident edge facings...
        if (verboseLevel >= 1) System.out.println("      computing vert facings");
        // bleah, need some other value for "not yet initialized"
        assert(-1 != FACING_UNKNOWN);
        VecMath.fillvec(vertFacings, -1);
        FORI (iEdge, nEdges)
        {
            // only need to do initial vertex-- edge.opposite() will do final vertex
            Mesh.Vertex v0 = mesh.getEdge(iEdge).initialVertex();
            if (v0 == null)
                continue;
            int i0 = v0.myIndex();
            if (vertFacings[i0] == -1) // uninitialized
                vertFacings[i0] = edgeFacings[iEdge];
            else if (vertFacings[i0] == FACING_UNKNOWN || edgeFacings[iEdge] == FACING_UNKNOWN)
                vertFacings[i0] = FACING_UNKNOWN;
            else if (vertFacings[i0] != edgeFacings[iEdge])
                vertFacings[i0] = FACING_SIDE;
            // otherwise leave it what it is
        }
        FORI (iVert, vertFacings.length)
        {
            if (vertFacings[iVert] == -1)
                vertFacings[iVert] = FACING_UNKNOWN;
        }

        // UNKNOWN in vertFacings means either it's an isolated vert,
        // or it's incident on an edge with UNKNOWN facing.

        if (verboseLevel >= 1)
        {
            OUT("      --------");
            final char facingToChar[] = {'?','-','0','+'};
            {
                StringBuffer sb = new StringBuffer();
                FORI (i, faceFacings.length)
                    sb.append(facingToChar[faceFacings[i]]);
                System.out.println("      face facings: "+sb);
            }
            {
                StringBuffer sb = new StringBuffer();
                FORI (i, edgeFacings.length)
                    sb.append(facingToChar[edgeFacings[i]]);
                System.out.println("      edge facings: "+sb);
            }
            {
                StringBuffer sb = new StringBuffer();
                FORI (i, vertFacings.length)
                    sb.append(facingToChar[vertFacings[i]]);
                System.out.println("      vert facings: "+sb);
            }
            OUT("      --------");
        }
        if (verboseLevel >= 1) System.out.println("    out getFacings");
    } // getFacings

    // CBB: probably doesn't work unless faces are convex
    // CBB: point can fall through cracks
    public static Mesh.Edge findSomeEdgeOnFaceVertIsIn(Mesh mesh, double x, double y)
    {

        boolean kissed = false;
        double twiceMostNegativeFaceArea = Double.POSITIVE_INFINITY;
        Mesh.Edge edgeOnMostNegativeFace = null;
        // XXX traverses each face of size n n times!  need to keep track of what we've done already
        int nEdges = mesh.edges.size();
        FORI (iEdge, nEdges)
        {
            boolean thisFaceIsGoodSoFar = true;
            Mesh.Edge edgeI = mesh.getEdge(iEdge);
            double twiceThisFaceArea = 0.;
            for (Mesh.Edge edge = edgeI;;)
            {
                double twiceThisTriArea = GeomUtils.twiceTriangleArea(
                    x, y,
                    edge.initialVertex().x(),
                    edge.initialVertex().y(),
                    edge.finalVertex().x(),
                    edge.finalVertex().y());
                if (twiceThisTriArea < 0)
                {
                    thisFaceIsGoodSoFar = false;
                    break; // out of this face
                }

                if ((edge = edge.next()) == edgeI)
                    break;
            }
            if (thisFaceIsGoodSoFar)
                return edgeI;
        }
        return null;
    } // findSomeEdgeOnFaceVertIsIn

    public static Mesh.Edge findSomeEdgeOnMostNegativeFace(Mesh mesh)
    {
        double twiceMostNegativeFaceArea = Double.POSITIVE_INFINITY;
        Mesh.Edge answer = null;
        int nEdges = mesh.edges.size();
        FORI (iEdge, nEdges)
        {
            Mesh.Edge edgeI = mesh.getEdge(iEdge);
            double x0 = edgeI.initialVertex().x();
            double y0 = edgeI.initialVertex().y();
            double twiceThisFaceArea = 0.;
            for (Mesh.Edge edge = edgeI;;)
            {
                double twiceThisTriArea = GeomUtils.twiceTriangleArea(
                    x0, y0,
                    edge.initialVertex().x(),
                    edge.initialVertex().y(),
                    edge.finalVertex().x(),
                    edge.finalVertex().y());
                twiceThisFaceArea += twiceThisTriArea;

                if ((edge = edge.next()) == edgeI)
                    break;
            }
            if (twiceThisFaceArea < twiceMostNegativeFaceArea)
            {
                twiceMostNegativeFaceArea = twiceThisFaceArea;
                answer = edgeI;
            }
        }
        return answer;
    } // findSomeEdgeOnMostNegativeFace

    public static double[][/*3*/] parseRadialHeightFieldPairs(String text)
    {
        String tokens[] = com.donhatchsw.compat.regex.split(text.trim(), "\\s+");
        if (tokens.length == 1 && tokens[0].equals("")) tokens = new String[]{}; // fix tokenization
        //PRINTARRAY(tokens);
        if (tokens.length % 2 != 0) return null;
        double pairs[][] = new double[tokens.length/2][2];
        FORI (i, tokens.length)
        {
            try
            {
                pairs[i/2][i%2] = Double.parseDouble(tokens[i]);
            }
            catch (NumberFormatException err)
            {
                return null;
            }
        }
        for (int i = 1; i < pairs.length; ++i)
        {
            if (!(pairs[i][0] >= (i==0?0.:pairs[i-1][0]))) return null; // radii must be nonnegative and nondecreasing
            if (!(pairs[i][1] >= (i==0?0.:pairs[i-1][1]))) return null; // dual radii must be nonnegative and nondecreasing
        }
        return pairs;
    } // parseRadialHeightFieldPairs

    // Sample:
    //   .06 .095 .14 .105    .16 .195 .24 .205    .26 .295  .34 .305  .36 .395  .44 .405  .46 .495
    //
    // Did this:
    //   Just noise 1000
    //   delaunayized on
    //   prewarp
    //   apply radial match (with above)
    //   delaunayized off
    //   "maybe make more difficult by truncating"
    //   start with upward Net
    //   make good
    // Haha, thought I found a counterexample for a few minutes!  But I think I applied radial match with delaunayized off :-(
    //
    public static void preWarpMeshForRadialHeightField(Mesh mesh, double pairs[][/*2*/])
    {
        if (pairs.length > 0) // prevent index out of bounds
        {
            FORIDOWN (iVert, mesh.verts.size())
            {
                Mesh.Vertex vert = mesh.getVert(iVert);
                // Treat initial x,y as target x,y in dual
                double xInDual = vert.x();
                double yInDual = vert.y();
                double rInDual = MyMath.hypot(xInDual, yInDual);

                // Find rInPrimal by mapping backwards.
                // Find interval [r0,r1) containing rInDual...
                // i is index of the upper end.
                int i = 0;
                while (i < pairs.length && rInDual >= pairs[i][1])
                    i++;
                double r0InDual = (i==0 ? 0. : pairs[i-1][1]);
                double r1InDual = (i==pairs.length ? pairs[i-1][1]+1+rInDual : pairs[i][1]);
                assert(INRANGE(r0InDual <=, rInDual, < r1InDual));
                double frac = (rInDual-r0InDual) / (r1InDual-r0InDual);
                assert(INRANGE(0 <=, frac, < 1));
                double r0InPrimal = (i==0 ? 0. : pairs[i-1][0]);
                double r1InPrimal = (i==pairs.length ? pairs[i-1][0]+1+rInDual : pairs[i][0]);
                double rInPrimal = LERP(r0InPrimal, r1InPrimal, frac);
                double scale = rInPrimal==0. ? 42. : rInPrimal / rInDual; // avoid zero divide
                double xInPrimal = xInDual * scale;
                double yInPrimal = yInDual * scale;
                if (false)
                {
                    OUT("===============");
                    PRINT(xInDual);
                    PRINT(yInDual);
                    PRINT(rInDual);
                    PRINT(r0InDual);
                    PRINT(r1InDual);
                    PRINT(frac);
                    PRINT(r0InPrimal);
                    PRINT(r1InPrimal);
                    PRINT(xInPrimal);
                    PRINT(yInPrimal);
                    OUT("===============");
                }
                vert.setxyh(xInPrimal, yInPrimal, vert.h());
            }
        }
    } // preWarpMeshForRadialHeightField
    public static void unPreWarpMeshForRadialHeightField(Mesh mesh, double pairs[][/*2*/])
    {
        double reversedPairs[][] = new double[pairs.length][2];
        FORI (i, pairs.length)
        {
            reversedPairs[i][0] = pairs[i][1];
            reversedPairs[i][1] = pairs[i][0];
        }
        preWarpMeshForRadialHeightField(mesh, reversedPairs);
    } // unPreWarpMeshForRadialHeightField


    // TODO: move to MeshUtils probably
    // Apply a radial height field.
    // The spec is an array of pairs {primalRadius, dualRadius},
    // (where each dualRadius manifests as a slope in the primal).

    // Hmm, trying to solve the following from outward net only makes it worse:
    // (this was when I expressed the radial height field as triples)
    //      blue noise 4000, delaunayized
    //      0 0 .1  .1 0 10  .2 0 .1 .3 0 10  .4 0 .1  .5 0 10
    //
    //      just noise 1000, delaunayized
    //      0 0 .1  .2 .25 .1  .4 1 .1 
    // however, starting from upwards net usually solves it.  hmm.
    public static void applyRadialHeightFieldPairsToMesh(Mesh mesh, double pairs[][])
    {
        int verboseLevel = 2; // 1: in/out, 2: nice description, 3: gory
        if (verboseLevel >= 1) OUT("    in applyRadialHeightFieldPairsToMesh(pairs="+Arrays.toStringCompact(pairs)+")");
        // Assumes all values are nonnegative and nondecreasing, since generated by parseRadialHeightFieldPairs

        double radii[] = new double[pairs.length + 1];
        double positions[] = new double[pairs.length + 1];
        double velocities[] = new double[pairs.length + 1];
        double accelerations[] = new double[pairs.length + 1];
        {
            double r = 0.; // accumulated radius in primal
            double p = 0.; // accumulated position (height)
            double v = 0.; // accumulated velocity (radius in dual)
            double a = 0.; // accumulated acceleration
        }
        if (true)
        {
            radii[0] = 0.;
            positions[0] = 0.;
            velocities[0] = 0.;
            FORI (i, pairs.length)
            {
                radii[i+1] = pairs[i][0];
                velocities[i+1] = pairs[i][1];
                double dt = radii[i+1] - radii[i];
                double dv = velocities[i+1] - velocities[i];
                accelerations[i] = dv / dt; // ok if infinite, that means this interval won't be used for calculations
                if (false)
                {
                    // Correct but blows up if acceleration is infinite
                    positions[i+1] = positions[i] + velocities[i]*dt + .5*accelerations[i]*(dt*dt);
                }
                else
                {
                    // Note that accelerations[i]*(dt*dt) == dv*dt,
                    // which avoids zero-divide.
                    positions[i+1] = positions[i] + velocities[i]*dt + .5*dv*dt;
                }
            }
            accelerations[pairs.length] = 1.; // so primal matches dual out to infinity
        }

        if (true)
        {
            if (verboseLevel >= 2) OUT("      Description:");
            FORI (i, pairs.length+1)
            {
                if (verboseLevel >= 2) OUT("          r = "+radii[i]+" (radius in primal)");
                if (verboseLevel >= 2) OUT("              p = "+positions[i]);
                if (verboseLevel >= 2) OUT("              v = "+velocities[i]+" (radius in dual)");
                if (verboseLevel >= 2) OUT("              a = "+accelerations[i]);
            }
        }
        if (verboseLevel >= 2) PRINTVEC(radii);
        if (verboseLevel >= 2) PRINTVEC(positions);
        if (verboseLevel >= 2) PRINTVEC(velocities);
        if (verboseLevel >= 2) PRINTVEC(accelerations);

        FORIDOWN (iVert, mesh.verts.size())
        {
            Mesh.Vertex vert = mesh.getVert(iVert);
            double x = vert.x();
            double y = vert.y();
            double r = MyMath.hypot(x, y);
            if (verboseLevel >= 3) OUT("==========");
            if (verboseLevel >= 3) PRINT(iVert);
            if (verboseLevel >= 3) PRINT(x);
            if (verboseLevel >= 3) PRINT(y);
            if (verboseLevel >= 3) PRINT(r);

            int i = 0;
            // could do binary search but whatever.
            // find the interval [r0,r1) that contains r.
            while (i+1 < radii.length && r >= radii[i+1])
                i++;
            if (verboseLevel >= 3) PRINT(i);

            double t = r - radii[i];
            if (verboseLevel >= 3) PRINT(t);
            assert(1./accelerations[i] != 0.); // not infinite
            assert(accelerations[i] == accelerations[i]); // not NaN
            double h = positions[i] + velocities[i]*t + .5*accelerations[i]*(t*t);
            if (verboseLevel >= 3) PRINT(h);

            // we were doing positive, but really should be concave with mouth downwards
            h *= -1;
            if (verboseLevel >= 3) PRINT(h);
            // change to offset from canonical paraboloid
            h -= -.5*r*r;
            if (verboseLevel >= 3) PRINT(h);
            if (verboseLevel >= 3) OUT("==========");

            vert.setxyh(x, y, h);
        }
        if (verboseLevel >= 1) OUT("    out applyRadialHeightFieldPairsToMesh(pairs="+Arrays.toStringCompact(pairs)+")");
    } // applyRadialHeightFieldPairsToMesh

    public static Mesh.Edge[] getVertToFirstEdgeOut(Mesh mesh)
    {
        int nVerts = mesh.verts.size();
        int nEdges = mesh.edges.size();
        Mesh.Edge answer[] = new Mesh.Edge[nVerts]; // all null initially
        FORI (iEdge, nEdges)
        {
            Mesh.Edge edge = mesh.getEdge(iEdge);
            Mesh.Vertex initialVertex = edge.initialVertex();
            if (initialVertex != null)
            {
                int iVert = initialVertex.myIndex();
                if (answer[iVert] == null)
                    answer[iVert] = edge;
            }
        }
        return answer;
    } // getVertToFirstEdgeOut

    // Greedily find a maximal list of verts such that no vert in the list has any neighbor in the list.
    public static int[] findMaximalIndependentVertexSet(Mesh mesh, java.util.Random rng)
    {
        int verboseLevel = 0;
        int nVerts = mesh.verts.size();
        int nEdges = mesh.edges.size();

        int answer[] = new int[nVerts]; // will shrink at end
        int answerSize = 0;

        Mesh.Edge vertToAnyEdgeOut[] = getVertToFirstEdgeOut(mesh);

        int vertIndexToCandidateIndex[] = VecMath.identityperm(nVerts);
        int candidates[] = VecMath.identityperm(nVerts);
        int nCandidates = nVerts;

        // Make verts incident on infinite edges ineligible
        FORI (iEdge, nEdges)
        {
            Mesh.Edge edge = mesh.getEdge(iEdge);
            if (edge.initialVertex() != null && edge.finalVertex() == null)
            {
                int iVert = edge.initialVertex().myIndex();
                int iCandidate = vertIndexToCandidateIndex[iVert];
                if (iCandidate != -1)
                {
                    assert(candidates[iCandidate] == iVert);
                    // dup code alert: same as below
                    vertIndexToCandidateIndex[candidates[nCandidates-1]] = iCandidate;
                    vertIndexToCandidateIndex[iVert] = -1;
                    candidates[iCandidate] = candidates[nCandidates-1];
                    candidates[nCandidates-1] = -1;
                    --nCandidates;
                }
            }
        }

        while (nCandidates > 0)
        {
            if (verboseLevel >= 2) OUT("      top of loop");
            if (verboseLevel >= 2) OUT("              answer = "+Arrays.toStringCompact(Arrays.subarray(answer, 0, answerSize)));
            if (verboseLevel >= 2) OUT("              candidates = "+Arrays.toStringCompact(Arrays.subarray(candidates, 0, nCandidates)));
            if (verboseLevel >= 2) OUT("              vertIndexToCandidateIndex = "+Arrays.toStringCompact(vertIndexToCandidateIndex));
            int iCandidate = rng.nextInt(nCandidates);
            if (verboseLevel >= 2) OUT("          iCandidate = "+iCandidate);
            int iVert = candidates[iCandidate];
            if (verboseLevel >= 2) OUT("          iVert = "+iVert);
            assert(vertIndexToCandidateIndex[iVert] == iCandidate);

            // Add it to the set
            answer[answerSize++] = iVert;

            // Remove it and all its neighbors from candidates list

            // dup code alert: same as below
            vertIndexToCandidateIndex[candidates[nCandidates-1]] = iCandidate;
            vertIndexToCandidateIndex[iVert] = -1;
            candidates[iCandidate] = candidates[nCandidates-1];
            candidates[nCandidates-1] = -1;
            --nCandidates;

            if (verboseLevel >= 2) OUT("          after transferring to answer:");
            if (verboseLevel >= 2) OUT("              answer = "+Arrays.toStringCompact(Arrays.subarray(answer, 0, answerSize)));
            if (verboseLevel >= 2) OUT("              candidates = "+Arrays.toStringCompact(Arrays.subarray(candidates, 0, nCandidates)));
            if (verboseLevel >= 2) OUT("              vertIndexToCandidateIndex = "+Arrays.toStringCompact(vertIndexToCandidateIndex));

            if (false)
            {
                // sanity check
                FORI (i, nCandidates)
                    assert(vertIndexToCandidateIndex[candidates[i]] == i);
                FORI (i, nVerts)
                    if (vertIndexToCandidateIndex[i] != -1)
                    {
                        assert(vertIndexToCandidateIndex[i] < nCandidates);
                        assert(candidates[vertIndexToCandidateIndex[i]] == i);
                    }
                for (int i = nCandidates; i < candidates.length; ++i)
                    assert(candidates[i] == -1);
            }

            Mesh.Edge edge0 = vertToAnyEdgeOut[iVert];
            assert(edge0 != null);
            Mesh.Edge edge = edge0;
            do {
                Mesh.Vertex finalVertex = edge.finalVertex();
                if (finalVertex != null)
                {
                    iVert = finalVertex.myIndex();
                    iCandidate = vertIndexToCandidateIndex[iVert];
                    if (iCandidate != -1)
                    {
                        if (verboseLevel >= 2) OUT("              neighbor v"+iVert+" is now ineligible");
                        assert(candidates[iCandidate] == iVert);

                        // dup code alert: same as above
                        vertIndexToCandidateIndex[candidates[nCandidates-1]] = iCandidate;
                        vertIndexToCandidateIndex[iVert] = -1;
                        candidates[iCandidate] = candidates[nCandidates-1];
                        candidates[nCandidates-1] = -1;
                        --nCandidates;
                    }
                    else
                    {
                        if (verboseLevel >= 2) OUT("              (neighbor v"+iVert+" already ineligible)");
                    }
                }
            } while ((edge = edge.opposite().next()) != edge0);
        }
        answer = (int[])Arrays.subarray(answer, 0, answerSize);
        return answer;
    } // findMaximalIndependentVertexSet

    // Observation: sometimes truncating a dual vertex
    // makes unfolding more difficult, in the sense that
    // something that was previously an unfolding is no longer.
    // See if we can exploit this.
    public static void maybeMakeMoreDifficultByTruncatingDual(Mesh mesh,
                                                              Mesh dualMesh,
                                                              double truncationFrac,
                                                              java.util.Random rng)
    {
        OUT("    in maybeMakeMoreDifficultByTruncatingDual");
        int nEdges = mesh.edges.size();
        assert(nEdges == dualMesh.edges.size());
        int nDualVerts = dualMesh.verts.size();

        // First find a maximal independent set of dual vertices (i.e. no pair of neighbors), greedily...
        int maximalIndependentDualVertSet[] = findMaximalIndependentVertexSet(dualMesh, rng);
        OUT("      maximalIndependentDualVertSet = "+Arrays.toStringCompact(maximalIndependentDualVertSet));
        OUT("      maximalIndependentDualVertSet.length = "+maximalIndependentDualVertSet.length);
        Mesh.Edge dualVertToFirstDualEdgeOut[] = getVertToFirstEdgeOut(dualMesh);

        double scratch[] = new double[3];
        FORI (i, maximalIndependentDualVertSet.length)
        {
            int iDualVert = maximalIndependentDualVertSet[i];
            Mesh.Edge dualEdge0 = dualVertToFirstDualEdgeOut[iDualVert];
            // dual mesh is trivalent, so...
            assert(dualEdge0.opposite().next()
                            .opposite().next()
                            .opposite().next() == dualEdge0);
            Mesh.Vertex v0 = dualMesh.getVert(iDualVert);
            Mesh.Vertex v1 = dualEdge0.finalVertex();
            Mesh.Vertex v2 = dualEdge0.opposite().next().finalVertex();
            Mesh.Vertex v3 = dualEdge0.opposite().next().opposite().next().finalVertex();

            double x0 = v0.x(), y0 = v0.y(), h0 = v0.h();
            double x1 = v1.x(), y1 = v1.y(), h1 = v1.h();
            double x2 = v2.x(), y2 = v2.y(), h2 = v2.h();
            double x3 = v3.x(), y3 = v3.y(), h3 = v3.h();

            // convert from height-above-paraboloid to euclidean ("actual")
            h0 -= .5 * (SQR(x0) + SQR(y0));
            h1 -= .5 * (SQR(x1) + SQR(y1));
            h2 -= .5 * (SQR(x2) + SQR(y2));
            h3 -= .5 * (SQR(x3) + SQR(y3));

            // lerp in euclidean space
            x1 = LERP(x0, x1, truncationFrac); y1 = LERP(y0, y1, truncationFrac); h1 = LERP(h0, h1, truncationFrac);
            x2 = LERP(x0, x2, truncationFrac); y2 = LERP(y0, y2, truncationFrac); h2 = LERP(h0, h2, truncationFrac);
            x3 = LERP(x0, x3, truncationFrac); y3 = LERP(y0, y3, truncationFrac); h3 = LERP(h0, h3, truncationFrac);

            // convert from euclidean back to height-above-paraboloid
            h0 += .5 * (SQR(x0) + SQR(y0));
            h1 += .5 * (SQR(x1) + SQR(y1));
            h2 += .5 * (SQR(x2) + SQR(y2));
            h3 += .5 * (SQR(x3) + SQR(y3));

            GeomUtils.SolveForDualPoint(x1, y1, h1,
                                        x2, y2, h2,
                                        x3, y3, h3,
                                        scratch,
                                        false,false,0.);
            double x = scratch[0];
            double y = scratch[1];
            double h = scratch[2];

            mesh.addIsolatedVertex(x, y, h);
            mesh.kisIsolatedVertex(mesh.getVert(mesh.verts.size()-1),
                                   mesh.getEdge(dualEdge0.opposite().myIndex())); // I had 50% chance of getting this right
        }
        OUT("    out maybeMakeMoreDifficultByTruncatingDual");
    } // maybeMakeMoreDifficultByTruncating

}  // class MeshUtils
